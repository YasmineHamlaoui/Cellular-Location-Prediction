{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('train.csv')\n",
    "mean_embeddings_df = pd.read_csv('sequence_esm1b_mean_embeddings_df.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "mean_embeddings_df = pd.read_csv('sequence_esm1b_mean_embeddings_df.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        ID                                           sequence  Kingdom  \\\n0  train_0  MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...  Metazoa   \n1  train_1  MAAAAAAAAALGVRLRDCCSRGAVLLLFFSLSPRPPAAAAWLLGLR...  Metazoa   \n2  train_2  MAAAAAAAAATEQQGSNGPVKKSMREKAVERRNVNKEHNSNFKAGY...  Metazoa   \n3  train_3  MAAAAAAAGAAGSAAPAAAAGAPGSGGAPSGSQGVLIGDRLYSGVL...  Metazoa   \n4  train_4  MAAAAAAGPSPGSGPGDSPEGPEGEAPERRRKAHGMLKLYYGLSEG...  Metazoa   \n\n   seq_len  Nucleus  Cytoplasm  Membrane  Cell membrane  Extracellular  \n0      306      1.0        1.0       0.0            0.0            0.0  \n1      951      0.0        0.0       1.0            1.0            0.0  \n2      320      0.0        1.0       1.0            1.0            0.0  \n3      520      1.0        0.0       0.0            0.0            0.0  \n4      782      0.0        0.0       0.0            0.0            0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>sequence</th>\n      <th>Kingdom</th>\n      <th>seq_len</th>\n      <th>Nucleus</th>\n      <th>Cytoplasm</th>\n      <th>Membrane</th>\n      <th>Cell membrane</th>\n      <th>Extracellular</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...</td>\n      <td>Metazoa</td>\n      <td>306</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>MAAAAAAAAALGVRLRDCCSRGAVLLLFFSLSPRPPAAAAWLLGLR...</td>\n      <td>Metazoa</td>\n      <td>951</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>MAAAAAAAAATEQQGSNGPVKKSMREKAVERRNVNKEHNSNFKAGY...</td>\n      <td>Metazoa</td>\n      <td>320</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>MAAAAAAAGAAGSAAPAAAAGAPGSGGAPSGSQGVLIGDRLYSGVL...</td>\n      <td>Metazoa</td>\n      <td>520</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>MAAAAAAGPSPGSGPGDSPEGPEGEAPERRRKAHGMLKLYYGLSEG...</td>\n      <td>Metazoa</td>\n      <td>782</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                                            sequence  mean_embeddings_1  \\\n0  MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...           0.138000   \n1  MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...           0.137180   \n2  MAAAAAAAAALGVRLRDCCSRGAVLLLFFSLSPRPPAAAAWLLGLR...           0.038339   \n3  MAAAAAAAAATEQQGSNGPVKKSMREKAVERRNVNKEHNSNFKAGY...          -0.022110   \n4  MAAAAAAAAATNGTGGSSGMEVDAAVVPSVMACGVTGSVSVALHPL...          -0.051710   \n\n   mean_embeddings_2  mean_embeddings_3  mean_embeddings_4  mean_embeddings_5  \\\n0           0.078087           0.048324           0.035530           0.013417   \n1           0.073386           0.044837           0.036080           0.016684   \n2           0.164428           0.153396           0.138865          -0.002554   \n3           0.271280           0.067028           0.057190           0.018684   \n4           0.353796           0.149786          -0.109090           0.012032   \n\n   mean_embeddings_6  mean_embeddings_7  mean_embeddings_8  mean_embeddings_9  \\\n0          -0.096783          -0.385766          -0.128247          -0.294128   \n1          -0.092217          -0.397141          -0.134102          -0.284217   \n2           0.002661          -0.288359          -0.006911          -0.049193   \n3          -0.030484          -0.005825          -0.028434          -0.245752   \n4          -0.096914          -0.229879           0.037871          -0.073446   \n\n   ...  mean_embeddings_1271  mean_embeddings_1272  mean_embeddings_1273  \\\n0  ...              0.383642             -0.084738             -0.215819   \n1  ...              0.380425             -0.079857             -0.207201   \n2  ...              0.243933             -0.017564             -0.265377   \n3  ...              0.249083             -0.091631             -0.249087   \n4  ...              0.402158             -0.074534             -0.124143   \n\n   mean_embeddings_1274  mean_embeddings_1275  mean_embeddings_1276  \\\n0             -0.065172             -0.514831              0.005591   \n1             -0.073626             -0.501474              0.005484   \n2             -0.022667             -0.370137             -0.085303   \n3              0.040271             -0.415228             -0.097675   \n4              0.052344             -0.414115              0.131673   \n\n   mean_embeddings_1277  mean_embeddings_1278  mean_embeddings_1279  \\\n0              0.045531             -0.137004             -0.135382   \n1              0.040341             -0.137553             -0.132132   \n2              0.096360             -0.074494             -0.115237   \n3              0.179024              0.058127              0.004434   \n4              0.130051             -0.029759             -0.169029   \n\n   mean_embeddings_1280  \n0              0.012397  \n1              0.009953  \n2              0.163367  \n3              0.080192  \n4              0.024629  \n\n[5 rows x 1281 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>mean_embeddings_1</th>\n      <th>mean_embeddings_2</th>\n      <th>mean_embeddings_3</th>\n      <th>mean_embeddings_4</th>\n      <th>mean_embeddings_5</th>\n      <th>mean_embeddings_6</th>\n      <th>mean_embeddings_7</th>\n      <th>mean_embeddings_8</th>\n      <th>mean_embeddings_9</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...</td>\n      <td>0.138000</td>\n      <td>0.078087</td>\n      <td>0.048324</td>\n      <td>0.035530</td>\n      <td>0.013417</td>\n      <td>-0.096783</td>\n      <td>-0.385766</td>\n      <td>-0.128247</td>\n      <td>-0.294128</td>\n      <td>...</td>\n      <td>0.383642</td>\n      <td>-0.084738</td>\n      <td>-0.215819</td>\n      <td>-0.065172</td>\n      <td>-0.514831</td>\n      <td>0.005591</td>\n      <td>0.045531</td>\n      <td>-0.137004</td>\n      <td>-0.135382</td>\n      <td>0.012397</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...</td>\n      <td>0.137180</td>\n      <td>0.073386</td>\n      <td>0.044837</td>\n      <td>0.036080</td>\n      <td>0.016684</td>\n      <td>-0.092217</td>\n      <td>-0.397141</td>\n      <td>-0.134102</td>\n      <td>-0.284217</td>\n      <td>...</td>\n      <td>0.380425</td>\n      <td>-0.079857</td>\n      <td>-0.207201</td>\n      <td>-0.073626</td>\n      <td>-0.501474</td>\n      <td>0.005484</td>\n      <td>0.040341</td>\n      <td>-0.137553</td>\n      <td>-0.132132</td>\n      <td>0.009953</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MAAAAAAAAALGVRLRDCCSRGAVLLLFFSLSPRPPAAAAWLLGLR...</td>\n      <td>0.038339</td>\n      <td>0.164428</td>\n      <td>0.153396</td>\n      <td>0.138865</td>\n      <td>-0.002554</td>\n      <td>0.002661</td>\n      <td>-0.288359</td>\n      <td>-0.006911</td>\n      <td>-0.049193</td>\n      <td>...</td>\n      <td>0.243933</td>\n      <td>-0.017564</td>\n      <td>-0.265377</td>\n      <td>-0.022667</td>\n      <td>-0.370137</td>\n      <td>-0.085303</td>\n      <td>0.096360</td>\n      <td>-0.074494</td>\n      <td>-0.115237</td>\n      <td>0.163367</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MAAAAAAAAATEQQGSNGPVKKSMREKAVERRNVNKEHNSNFKAGY...</td>\n      <td>-0.022110</td>\n      <td>0.271280</td>\n      <td>0.067028</td>\n      <td>0.057190</td>\n      <td>0.018684</td>\n      <td>-0.030484</td>\n      <td>-0.005825</td>\n      <td>-0.028434</td>\n      <td>-0.245752</td>\n      <td>...</td>\n      <td>0.249083</td>\n      <td>-0.091631</td>\n      <td>-0.249087</td>\n      <td>0.040271</td>\n      <td>-0.415228</td>\n      <td>-0.097675</td>\n      <td>0.179024</td>\n      <td>0.058127</td>\n      <td>0.004434</td>\n      <td>0.080192</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MAAAAAAAAATNGTGGSSGMEVDAAVVPSVMACGVTGSVSVALHPL...</td>\n      <td>-0.051710</td>\n      <td>0.353796</td>\n      <td>0.149786</td>\n      <td>-0.109090</td>\n      <td>0.012032</td>\n      <td>-0.096914</td>\n      <td>-0.229879</td>\n      <td>0.037871</td>\n      <td>-0.073446</td>\n      <td>...</td>\n      <td>0.402158</td>\n      <td>-0.074534</td>\n      <td>-0.124143</td>\n      <td>0.052344</td>\n      <td>-0.414115</td>\n      <td>0.131673</td>\n      <td>0.130051</td>\n      <td>-0.029759</td>\n      <td>-0.169029</td>\n      <td>0.024629</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 1281 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_embeddings_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "s = \"MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDYGNGLESEELEPEELLLEPEPEPEPEEEPPRPRAPPGAPGPGPGSGAPGSQEEEEEPGLVEGDPGDGAIEDPELEAIKARVREMEEEAEKLKELQNEVEKQMNMSPPPGNAGPVIMSIEEKMEADARSIYVGNVDYGATAEELEAHFHGCGSVNRVTILCDKFSGHPKGFAYIEFSDKESVRTSLALDESLFRGRQIKVIPKRTNRPGISTTDRGFPRARYRARTTNYNSSRSRFYSGFNSRPRGRVYRGRARATSWYSPY\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No axis named MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDYGNGLESEELEPEELLLEPEPEPEPEEEPPRPRAPPGAPGPGPGSGAPGSQEEEEEPGLVEGDPGDGAIEDPELEAIKARVREMEEEAEKLKELQNEVEKQMNMSPPPGNAGPVIMSIEEKMEADARSIYVGNVDYGATAEELEAHFHGCGSVNRVTILCDKFSGHPKGFAYIEFSDKESVRTSLALDESLFRGRQIKVIPKRTNRPGISTTDRGFPRARYRARTTNYNSSRSRFYSGFNSRPRGRVYRGRARATSWYSPY for object type <class 'pandas.core.series.Series'>",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-20-35c90570f579>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmean_embeddings_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"sequence\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ms\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/ai2e/lib/python3.7/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, axis)\u001B[0m\n\u001B[1;32m    576\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    577\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0maxis\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 578\u001B[0;31m             \u001B[0maxis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_axis_number\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    579\u001B[0m         \u001B[0mnew_self\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maxis\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    580\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mnew_self\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ai2e/lib/python3.7/site-packages/pandas/core/generic.py\u001B[0m in \u001B[0;36m_get_axis_number\u001B[0;34m(cls, axis)\u001B[0m\n\u001B[1;32m    405\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mKeyError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    406\u001B[0m                 \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 407\u001B[0;31m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"No axis named {axis} for object type {cls}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    408\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    409\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: No axis named MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDYGNGLESEELEPEELLLEPEPEPEPEEEPPRPRAPPGAPGPGPGSGAPGSQEEEEEPGLVEGDPGDGAIEDPELEAIKARVREMEEEAEKLKELQNEVEKQMNMSPPPGNAGPVIMSIEEKMEADARSIYVGNVDYGATAEELEAHFHGCGSVNRVTILCDKFSGHPKGFAYIEFSDKESVRTSLALDESLFRGRQIKVIPKRTNRPGISTTDRGFPRARYRARTTNYNSSRSRFYSGFNSRPRGRVYRGRARATSWYSPY for object type <class 'pandas.core.series.Series'>"
     ]
    }
   ],
   "source": [
    "mean_embeddings_df[\"sequence\"].loc(s)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "   mean_embeddings_1  mean_embeddings_2  mean_embeddings_3  mean_embeddings_4  \\\n1            0.13718           0.073386           0.044837            0.03608   \n\n   mean_embeddings_5  mean_embeddings_6  mean_embeddings_7  mean_embeddings_8  \\\n1           0.016684          -0.092217          -0.397141          -0.134102   \n\n   mean_embeddings_9  mean_embeddings_10  ...  mean_embeddings_1271  \\\n1          -0.284217           -0.141342  ...              0.380425   \n\n   mean_embeddings_1272  mean_embeddings_1273  mean_embeddings_1274  \\\n1             -0.079857             -0.207201             -0.073626   \n\n   mean_embeddings_1275  mean_embeddings_1276  mean_embeddings_1277  \\\n1             -0.501474              0.005484              0.040341   \n\n   mean_embeddings_1278  mean_embeddings_1279  mean_embeddings_1280  \n1             -0.137553             -0.132132              0.009953  \n\n[1 rows x 1280 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_embeddings_1</th>\n      <th>mean_embeddings_2</th>\n      <th>mean_embeddings_3</th>\n      <th>mean_embeddings_4</th>\n      <th>mean_embeddings_5</th>\n      <th>mean_embeddings_6</th>\n      <th>mean_embeddings_7</th>\n      <th>mean_embeddings_8</th>\n      <th>mean_embeddings_9</th>\n      <th>mean_embeddings_10</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.13718</td>\n      <td>0.073386</td>\n      <td>0.044837</td>\n      <td>0.03608</td>\n      <td>0.016684</td>\n      <td>-0.092217</td>\n      <td>-0.397141</td>\n      <td>-0.134102</td>\n      <td>-0.284217</td>\n      <td>-0.141342</td>\n      <td>...</td>\n      <td>0.380425</td>\n      <td>-0.079857</td>\n      <td>-0.207201</td>\n      <td>-0.073626</td>\n      <td>-0.501474</td>\n      <td>0.005484</td>\n      <td>0.040341</td>\n      <td>-0.137553</td>\n      <td>-0.132132</td>\n      <td>0.009953</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 1280 columns</p>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_embeddings_df[mean_embeddings_df[\"sequence\"] == s].iloc[:, 1:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-e5da080b780a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmean_embeddings_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mon\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"sequence\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"inner\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/ai2e/lib/python3.7/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36mjoin\u001B[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001B[0m\n\u001B[1;32m   7207\u001B[0m         \"\"\"\n\u001B[1;32m   7208\u001B[0m         return self._join_compat(\n\u001B[0;32m-> 7209\u001B[0;31m             \u001B[0mother\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mon\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mon\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhow\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mhow\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlsuffix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlsuffix\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrsuffix\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrsuffix\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msort\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msort\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   7210\u001B[0m         )\n\u001B[1;32m   7211\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ai2e/lib/python3.7/site-packages/pandas/core/frame.py\u001B[0m in \u001B[0;36m_join_compat\u001B[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001B[0m\n\u001B[1;32m   7230\u001B[0m                 \u001B[0mright_index\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   7231\u001B[0m                 \u001B[0msuffixes\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlsuffix\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrsuffix\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 7232\u001B[0;31m                 \u001B[0msort\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msort\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   7233\u001B[0m             )\n\u001B[1;32m   7234\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ai2e/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36mmerge\u001B[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001B[0m\n\u001B[1;32m     84\u001B[0m         \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcopy\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     85\u001B[0m         \u001B[0mindicator\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mindicator\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 86\u001B[0;31m         \u001B[0mvalidate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvalidate\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     87\u001B[0m     )\n\u001B[1;32m     88\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ai2e/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001B[0m\n\u001B[1;32m    629\u001B[0m         \u001B[0;31m# validate the merge keys dtypes. We may need to coerce\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    630\u001B[0m         \u001B[0;31m# to avoid incompat dtypes\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 631\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_coerce_merge_keys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    632\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    633\u001B[0m         \u001B[0;31m# If argument passed to validate,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ai2e/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001B[0m in \u001B[0;36m_maybe_coerce_merge_keys\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1144\u001B[0m                     \u001B[0minferred_right\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mstring_types\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0minferred_left\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mstring_types\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1145\u001B[0m                 ):\n\u001B[0;32m-> 1146\u001B[0;31m                     \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1147\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1148\u001B[0m             \u001B[0;31m# datetimelikes must match exactly\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "df.join(mean_embeddings_df, on=\"sequence\", how=\"inner\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = df.merge(mean_embeddings_df, left_on='sequence', right_on='sequence')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "                ID                                           sequence  \\\n0          train_0  MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...   \n1          train_1  MAAAAAAAAALGVRLRDCCSRGAVLLLFFSLSPRPPAAAAWLLGLR...   \n2          train_2  MAAAAAAAAATEQQGSNGPVKKSMREKAVERRNVNKEHNSNFKAGY...   \n3          train_3  MAAAAAAAGAAGSAAPAAAAGAPGSGGAPSGSQGVLIGDRLYSGVL...   \n4          train_4  MAAAAAAGPSPGSGPGDSPEGPEGEAPERRRKAHGMLKLYYGLSEG...   \n...            ...                                                ...   \n18201  train_18201  MYWVLLCGSILLCCLSGASASPAKTKMYGKLPLVLTDACMGVLGEV...   \n18202  train_18202  MYYFSRVAARTFCCCIFFCLATAYSRPDRNPRKIEKKDKKFFGASK...   \n18203  train_18203  MYYGISQFSEAYNKILRNSSSHSSCQLVIFVSCLNIDALCATKMLS...   \n18204  train_18204  MYYQNQHQGKNILSSSRMHITSERHPFLRGNSPGDSGLILSTDAKP...   \n18205  train_18205  MYYYLEIECESPVKDIFTCNKRRASKVVGNSFGGDHFNFRLGEIKL...   \n\n             Kingdom  seq_len  Nucleus  Cytoplasm  Membrane  Cell membrane  \\\n0            Metazoa      306      1.0        1.0       0.0            0.0   \n1            Metazoa      951      0.0        0.0       1.0            1.0   \n2            Metazoa      320      0.0        1.0       1.0            1.0   \n3            Metazoa      520      1.0        0.0       0.0            0.0   \n4            Metazoa      782      0.0        0.0       0.0            0.0   \n...              ...      ...      ...        ...       ...            ...   \n18201          Fungi      711      0.0        0.0       1.0            1.0   \n18202          Fungi      126      0.0        0.0       0.0            0.0   \n18203          Fungi      650      1.0        0.0       0.0            0.0   \n18204  Viridiplantae      394      1.0        0.0       0.0            0.0   \n18205          Fungi      547      0.0        1.0       0.0            0.0   \n\n       Extracellular  mean_embeddings_1  ...  mean_embeddings_1271  \\\n0                0.0           0.137180  ...              0.380425   \n1                0.0           0.038339  ...              0.243933   \n2                0.0          -0.022110  ...              0.249083   \n3                0.0          -0.121040  ...              0.227777   \n4                0.0          -0.078910  ...              0.313915   \n...              ...                ...  ...                   ...   \n18201            0.0           0.031714  ...              0.230494   \n18202            0.0          -0.012318  ...              0.095944   \n18203            0.0          -0.010492  ...              0.131282   \n18204            0.0           0.142669  ...              0.239682   \n18205            0.0           0.077811  ...              0.243689   \n\n       mean_embeddings_1272  mean_embeddings_1273  mean_embeddings_1274  \\\n0                 -0.079857             -0.207201             -0.073626   \n1                 -0.017564             -0.265377             -0.022667   \n2                 -0.091631             -0.249087              0.040271   \n3                 -0.035011             -0.228398             -0.182060   \n4                 -0.165890             -0.182905             -0.105171   \n...                     ...                   ...                   ...   \n18201             -0.014877             -0.070507              0.092372   \n18202             -0.031087             -0.098680              0.103855   \n18203             -0.077521             -0.328603              0.149159   \n18204              0.000409             -0.190628             -0.047931   \n18205             -0.052412             -0.022390              0.077389   \n\n       mean_embeddings_1275  mean_embeddings_1276  mean_embeddings_1277  \\\n0                 -0.501474              0.005484              0.040341   \n1                 -0.370137             -0.085303              0.096360   \n2                 -0.415228             -0.097675              0.179024   \n3                 -0.365424              0.151473              0.101917   \n4                 -0.435850              0.146480              0.102739   \n...                     ...                   ...                   ...   \n18201             -0.097430              0.026271              0.038775   \n18202             -1.264032             -0.091464              0.111977   \n18203             -0.601662              0.151903              0.200224   \n18204             -0.513402              0.081698              0.118012   \n18205             -0.441519             -0.017692              0.086533   \n\n       mean_embeddings_1278  mean_embeddings_1279  mean_embeddings_1280  \n0                 -0.137553             -0.132132              0.009953  \n1                 -0.074494             -0.115237              0.163367  \n2                  0.058127              0.004434              0.080192  \n3                 -0.043787             -0.066641              0.078485  \n4                 -0.040836             -0.302047             -0.037148  \n...                     ...                   ...                   ...  \n18201              0.046432              0.007080             -0.010476  \n18202              0.028506              0.110201              0.197081  \n18203             -0.043059             -0.091404             -0.073244  \n18204             -0.053121             -0.085886              0.228701  \n18205              0.026601             -0.158437              0.124761  \n\n[18206 rows x 1289 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>sequence</th>\n      <th>Kingdom</th>\n      <th>seq_len</th>\n      <th>Nucleus</th>\n      <th>Cytoplasm</th>\n      <th>Membrane</th>\n      <th>Cell membrane</th>\n      <th>Extracellular</th>\n      <th>mean_embeddings_1</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...</td>\n      <td>Metazoa</td>\n      <td>306</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.137180</td>\n      <td>...</td>\n      <td>0.380425</td>\n      <td>-0.079857</td>\n      <td>-0.207201</td>\n      <td>-0.073626</td>\n      <td>-0.501474</td>\n      <td>0.005484</td>\n      <td>0.040341</td>\n      <td>-0.137553</td>\n      <td>-0.132132</td>\n      <td>0.009953</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>MAAAAAAAAALGVRLRDCCSRGAVLLLFFSLSPRPPAAAAWLLGLR...</td>\n      <td>Metazoa</td>\n      <td>951</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.038339</td>\n      <td>...</td>\n      <td>0.243933</td>\n      <td>-0.017564</td>\n      <td>-0.265377</td>\n      <td>-0.022667</td>\n      <td>-0.370137</td>\n      <td>-0.085303</td>\n      <td>0.096360</td>\n      <td>-0.074494</td>\n      <td>-0.115237</td>\n      <td>0.163367</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>MAAAAAAAAATEQQGSNGPVKKSMREKAVERRNVNKEHNSNFKAGY...</td>\n      <td>Metazoa</td>\n      <td>320</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>-0.022110</td>\n      <td>...</td>\n      <td>0.249083</td>\n      <td>-0.091631</td>\n      <td>-0.249087</td>\n      <td>0.040271</td>\n      <td>-0.415228</td>\n      <td>-0.097675</td>\n      <td>0.179024</td>\n      <td>0.058127</td>\n      <td>0.004434</td>\n      <td>0.080192</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>MAAAAAAAGAAGSAAPAAAAGAPGSGGAPSGSQGVLIGDRLYSGVL...</td>\n      <td>Metazoa</td>\n      <td>520</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.121040</td>\n      <td>...</td>\n      <td>0.227777</td>\n      <td>-0.035011</td>\n      <td>-0.228398</td>\n      <td>-0.182060</td>\n      <td>-0.365424</td>\n      <td>0.151473</td>\n      <td>0.101917</td>\n      <td>-0.043787</td>\n      <td>-0.066641</td>\n      <td>0.078485</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>MAAAAAAGPSPGSGPGDSPEGPEGEAPERRRKAHGMLKLYYGLSEG...</td>\n      <td>Metazoa</td>\n      <td>782</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.078910</td>\n      <td>...</td>\n      <td>0.313915</td>\n      <td>-0.165890</td>\n      <td>-0.182905</td>\n      <td>-0.105171</td>\n      <td>-0.435850</td>\n      <td>0.146480</td>\n      <td>0.102739</td>\n      <td>-0.040836</td>\n      <td>-0.302047</td>\n      <td>-0.037148</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18201</th>\n      <td>train_18201</td>\n      <td>MYWVLLCGSILLCCLSGASASPAKTKMYGKLPLVLTDACMGVLGEV...</td>\n      <td>Fungi</td>\n      <td>711</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.031714</td>\n      <td>...</td>\n      <td>0.230494</td>\n      <td>-0.014877</td>\n      <td>-0.070507</td>\n      <td>0.092372</td>\n      <td>-0.097430</td>\n      <td>0.026271</td>\n      <td>0.038775</td>\n      <td>0.046432</td>\n      <td>0.007080</td>\n      <td>-0.010476</td>\n    </tr>\n    <tr>\n      <th>18202</th>\n      <td>train_18202</td>\n      <td>MYYFSRVAARTFCCCIFFCLATAYSRPDRNPRKIEKKDKKFFGASK...</td>\n      <td>Fungi</td>\n      <td>126</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.012318</td>\n      <td>...</td>\n      <td>0.095944</td>\n      <td>-0.031087</td>\n      <td>-0.098680</td>\n      <td>0.103855</td>\n      <td>-1.264032</td>\n      <td>-0.091464</td>\n      <td>0.111977</td>\n      <td>0.028506</td>\n      <td>0.110201</td>\n      <td>0.197081</td>\n    </tr>\n    <tr>\n      <th>18203</th>\n      <td>train_18203</td>\n      <td>MYYGISQFSEAYNKILRNSSSHSSCQLVIFVSCLNIDALCATKMLS...</td>\n      <td>Fungi</td>\n      <td>650</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.010492</td>\n      <td>...</td>\n      <td>0.131282</td>\n      <td>-0.077521</td>\n      <td>-0.328603</td>\n      <td>0.149159</td>\n      <td>-0.601662</td>\n      <td>0.151903</td>\n      <td>0.200224</td>\n      <td>-0.043059</td>\n      <td>-0.091404</td>\n      <td>-0.073244</td>\n    </tr>\n    <tr>\n      <th>18204</th>\n      <td>train_18204</td>\n      <td>MYYQNQHQGKNILSSSRMHITSERHPFLRGNSPGDSGLILSTDAKP...</td>\n      <td>Viridiplantae</td>\n      <td>394</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.142669</td>\n      <td>...</td>\n      <td>0.239682</td>\n      <td>0.000409</td>\n      <td>-0.190628</td>\n      <td>-0.047931</td>\n      <td>-0.513402</td>\n      <td>0.081698</td>\n      <td>0.118012</td>\n      <td>-0.053121</td>\n      <td>-0.085886</td>\n      <td>0.228701</td>\n    </tr>\n    <tr>\n      <th>18205</th>\n      <td>train_18205</td>\n      <td>MYYYLEIECESPVKDIFTCNKRRASKVVGNSFGGDHFNFRLGEIKL...</td>\n      <td>Fungi</td>\n      <td>547</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.077811</td>\n      <td>...</td>\n      <td>0.243689</td>\n      <td>-0.052412</td>\n      <td>-0.022390</td>\n      <td>0.077389</td>\n      <td>-0.441519</td>\n      <td>-0.017692</td>\n      <td>0.086533</td>\n      <td>0.026601</td>\n      <td>-0.158437</td>\n      <td>0.124761</td>\n    </tr>\n  </tbody>\n</table>\n<p>18206 rows × 1289 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "del mean_embeddings_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "del df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "data['Kingdom'] = pd.Categorical(data.Kingdom)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "                ID                                           sequence  \\\n0          train_0  MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...   \n1          train_1  MAAAAAAAAALGVRLRDCCSRGAVLLLFFSLSPRPPAAAAWLLGLR...   \n2          train_2  MAAAAAAAAATEQQGSNGPVKKSMREKAVERRNVNKEHNSNFKAGY...   \n3          train_3  MAAAAAAAGAAGSAAPAAAAGAPGSGGAPSGSQGVLIGDRLYSGVL...   \n4          train_4  MAAAAAAGPSPGSGPGDSPEGPEGEAPERRRKAHGMLKLYYGLSEG...   \n...            ...                                                ...   \n18201  train_18201  MYWVLLCGSILLCCLSGASASPAKTKMYGKLPLVLTDACMGVLGEV...   \n18202  train_18202  MYYFSRVAARTFCCCIFFCLATAYSRPDRNPRKIEKKDKKFFGASK...   \n18203  train_18203  MYYGISQFSEAYNKILRNSSSHSSCQLVIFVSCLNIDALCATKMLS...   \n18204  train_18204  MYYQNQHQGKNILSSSRMHITSERHPFLRGNSPGDSGLILSTDAKP...   \n18205  train_18205  MYYYLEIECESPVKDIFTCNKRRASKVVGNSFGGDHFNFRLGEIKL...   \n\n             Kingdom  seq_len  Nucleus  Cytoplasm  Membrane  Cell membrane  \\\n0            Metazoa      306      1.0        1.0       0.0            0.0   \n1            Metazoa      951      0.0        0.0       1.0            1.0   \n2            Metazoa      320      0.0        1.0       1.0            1.0   \n3            Metazoa      520      1.0        0.0       0.0            0.0   \n4            Metazoa      782      0.0        0.0       0.0            0.0   \n...              ...      ...      ...        ...       ...            ...   \n18201          Fungi      711      0.0        0.0       1.0            1.0   \n18202          Fungi      126      0.0        0.0       0.0            0.0   \n18203          Fungi      650      1.0        0.0       0.0            0.0   \n18204  Viridiplantae      394      1.0        0.0       0.0            0.0   \n18205          Fungi      547      0.0        1.0       0.0            0.0   \n\n       Extracellular  mean_embeddings_1  ...  mean_embeddings_1271  \\\n0                0.0           0.137180  ...              0.380425   \n1                0.0           0.038339  ...              0.243933   \n2                0.0          -0.022110  ...              0.249083   \n3                0.0          -0.121040  ...              0.227777   \n4                0.0          -0.078910  ...              0.313915   \n...              ...                ...  ...                   ...   \n18201            0.0           0.031714  ...              0.230494   \n18202            0.0          -0.012318  ...              0.095944   \n18203            0.0          -0.010492  ...              0.131282   \n18204            0.0           0.142669  ...              0.239682   \n18205            0.0           0.077811  ...              0.243689   \n\n       mean_embeddings_1272  mean_embeddings_1273  mean_embeddings_1274  \\\n0                 -0.079857             -0.207201             -0.073626   \n1                 -0.017564             -0.265377             -0.022667   \n2                 -0.091631             -0.249087              0.040271   \n3                 -0.035011             -0.228398             -0.182060   \n4                 -0.165890             -0.182905             -0.105171   \n...                     ...                   ...                   ...   \n18201             -0.014877             -0.070507              0.092372   \n18202             -0.031087             -0.098680              0.103855   \n18203             -0.077521             -0.328603              0.149159   \n18204              0.000409             -0.190628             -0.047931   \n18205             -0.052412             -0.022390              0.077389   \n\n       mean_embeddings_1275  mean_embeddings_1276  mean_embeddings_1277  \\\n0                 -0.501474              0.005484              0.040341   \n1                 -0.370137             -0.085303              0.096360   \n2                 -0.415228             -0.097675              0.179024   \n3                 -0.365424              0.151473              0.101917   \n4                 -0.435850              0.146480              0.102739   \n...                     ...                   ...                   ...   \n18201             -0.097430              0.026271              0.038775   \n18202             -1.264032             -0.091464              0.111977   \n18203             -0.601662              0.151903              0.200224   \n18204             -0.513402              0.081698              0.118012   \n18205             -0.441519             -0.017692              0.086533   \n\n       mean_embeddings_1278  mean_embeddings_1279  mean_embeddings_1280  \n0                 -0.137553             -0.132132              0.009953  \n1                 -0.074494             -0.115237              0.163367  \n2                  0.058127              0.004434              0.080192  \n3                 -0.043787             -0.066641              0.078485  \n4                 -0.040836             -0.302047             -0.037148  \n...                     ...                   ...                   ...  \n18201              0.046432              0.007080             -0.010476  \n18202              0.028506              0.110201              0.197081  \n18203             -0.043059             -0.091404             -0.073244  \n18204             -0.053121             -0.085886              0.228701  \n18205              0.026601             -0.158437              0.124761  \n\n[18206 rows x 1289 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>sequence</th>\n      <th>Kingdom</th>\n      <th>seq_len</th>\n      <th>Nucleus</th>\n      <th>Cytoplasm</th>\n      <th>Membrane</th>\n      <th>Cell membrane</th>\n      <th>Extracellular</th>\n      <th>mean_embeddings_1</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train_0</td>\n      <td>MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...</td>\n      <td>Metazoa</td>\n      <td>306</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.137180</td>\n      <td>...</td>\n      <td>0.380425</td>\n      <td>-0.079857</td>\n      <td>-0.207201</td>\n      <td>-0.073626</td>\n      <td>-0.501474</td>\n      <td>0.005484</td>\n      <td>0.040341</td>\n      <td>-0.137553</td>\n      <td>-0.132132</td>\n      <td>0.009953</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train_1</td>\n      <td>MAAAAAAAAALGVRLRDCCSRGAVLLLFFSLSPRPPAAAAWLLGLR...</td>\n      <td>Metazoa</td>\n      <td>951</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.038339</td>\n      <td>...</td>\n      <td>0.243933</td>\n      <td>-0.017564</td>\n      <td>-0.265377</td>\n      <td>-0.022667</td>\n      <td>-0.370137</td>\n      <td>-0.085303</td>\n      <td>0.096360</td>\n      <td>-0.074494</td>\n      <td>-0.115237</td>\n      <td>0.163367</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train_2</td>\n      <td>MAAAAAAAAATEQQGSNGPVKKSMREKAVERRNVNKEHNSNFKAGY...</td>\n      <td>Metazoa</td>\n      <td>320</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>-0.022110</td>\n      <td>...</td>\n      <td>0.249083</td>\n      <td>-0.091631</td>\n      <td>-0.249087</td>\n      <td>0.040271</td>\n      <td>-0.415228</td>\n      <td>-0.097675</td>\n      <td>0.179024</td>\n      <td>0.058127</td>\n      <td>0.004434</td>\n      <td>0.080192</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train_3</td>\n      <td>MAAAAAAAGAAGSAAPAAAAGAPGSGGAPSGSQGVLIGDRLYSGVL...</td>\n      <td>Metazoa</td>\n      <td>520</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.121040</td>\n      <td>...</td>\n      <td>0.227777</td>\n      <td>-0.035011</td>\n      <td>-0.228398</td>\n      <td>-0.182060</td>\n      <td>-0.365424</td>\n      <td>0.151473</td>\n      <td>0.101917</td>\n      <td>-0.043787</td>\n      <td>-0.066641</td>\n      <td>0.078485</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train_4</td>\n      <td>MAAAAAAGPSPGSGPGDSPEGPEGEAPERRRKAHGMLKLYYGLSEG...</td>\n      <td>Metazoa</td>\n      <td>782</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.078910</td>\n      <td>...</td>\n      <td>0.313915</td>\n      <td>-0.165890</td>\n      <td>-0.182905</td>\n      <td>-0.105171</td>\n      <td>-0.435850</td>\n      <td>0.146480</td>\n      <td>0.102739</td>\n      <td>-0.040836</td>\n      <td>-0.302047</td>\n      <td>-0.037148</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18201</th>\n      <td>train_18201</td>\n      <td>MYWVLLCGSILLCCLSGASASPAKTKMYGKLPLVLTDACMGVLGEV...</td>\n      <td>Fungi</td>\n      <td>711</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.031714</td>\n      <td>...</td>\n      <td>0.230494</td>\n      <td>-0.014877</td>\n      <td>-0.070507</td>\n      <td>0.092372</td>\n      <td>-0.097430</td>\n      <td>0.026271</td>\n      <td>0.038775</td>\n      <td>0.046432</td>\n      <td>0.007080</td>\n      <td>-0.010476</td>\n    </tr>\n    <tr>\n      <th>18202</th>\n      <td>train_18202</td>\n      <td>MYYFSRVAARTFCCCIFFCLATAYSRPDRNPRKIEKKDKKFFGASK...</td>\n      <td>Fungi</td>\n      <td>126</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.012318</td>\n      <td>...</td>\n      <td>0.095944</td>\n      <td>-0.031087</td>\n      <td>-0.098680</td>\n      <td>0.103855</td>\n      <td>-1.264032</td>\n      <td>-0.091464</td>\n      <td>0.111977</td>\n      <td>0.028506</td>\n      <td>0.110201</td>\n      <td>0.197081</td>\n    </tr>\n    <tr>\n      <th>18203</th>\n      <td>train_18203</td>\n      <td>MYYGISQFSEAYNKILRNSSSHSSCQLVIFVSCLNIDALCATKMLS...</td>\n      <td>Fungi</td>\n      <td>650</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.010492</td>\n      <td>...</td>\n      <td>0.131282</td>\n      <td>-0.077521</td>\n      <td>-0.328603</td>\n      <td>0.149159</td>\n      <td>-0.601662</td>\n      <td>0.151903</td>\n      <td>0.200224</td>\n      <td>-0.043059</td>\n      <td>-0.091404</td>\n      <td>-0.073244</td>\n    </tr>\n    <tr>\n      <th>18204</th>\n      <td>train_18204</td>\n      <td>MYYQNQHQGKNILSSSRMHITSERHPFLRGNSPGDSGLILSTDAKP...</td>\n      <td>Viridiplantae</td>\n      <td>394</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.142669</td>\n      <td>...</td>\n      <td>0.239682</td>\n      <td>0.000409</td>\n      <td>-0.190628</td>\n      <td>-0.047931</td>\n      <td>-0.513402</td>\n      <td>0.081698</td>\n      <td>0.118012</td>\n      <td>-0.053121</td>\n      <td>-0.085886</td>\n      <td>0.228701</td>\n    </tr>\n    <tr>\n      <th>18205</th>\n      <td>train_18205</td>\n      <td>MYYYLEIECESPVKDIFTCNKRRASKVVGNSFGGDHFNFRLGEIKL...</td>\n      <td>Fungi</td>\n      <td>547</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.077811</td>\n      <td>...</td>\n      <td>0.243689</td>\n      <td>-0.052412</td>\n      <td>-0.022390</td>\n      <td>0.077389</td>\n      <td>-0.441519</td>\n      <td>-0.017692</td>\n      <td>0.086533</td>\n      <td>0.026601</td>\n      <td>-0.158437</td>\n      <td>0.124761</td>\n    </tr>\n  </tbody>\n</table>\n<p>18206 rows × 1289 columns</p>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "       Kingdom_Fungi  Kingdom_Metazoa  Kingdom_Other  Kingdom_Viridiplantae\n0                  0                1              0                      0\n1                  0                1              0                      0\n2                  0                1              0                      0\n3                  0                1              0                      0\n4                  0                1              0                      0\n...              ...              ...            ...                    ...\n18201              1                0              0                      0\n18202              1                0              0                      0\n18203              1                0              0                      0\n18204              0                0              0                      1\n18205              1                0              0                      0\n\n[18206 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Kingdom_Fungi</th>\n      <th>Kingdom_Metazoa</th>\n      <th>Kingdom_Other</th>\n      <th>Kingdom_Viridiplantae</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18201</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18202</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18203</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18204</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18205</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>18206 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(data.Kingdom, prefix='Kingdom')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data = data.drop(columns = [\"ID\", \"Kingdom\", \"sequence\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "       seq_len  Nucleus  Cytoplasm  Membrane  Cell membrane  Extracellular  \\\n0          306      1.0        1.0       0.0            0.0            0.0   \n1          951      0.0        0.0       1.0            1.0            0.0   \n2          320      0.0        1.0       1.0            1.0            0.0   \n3          520      1.0        0.0       0.0            0.0            0.0   \n4          782      0.0        0.0       0.0            0.0            0.0   \n...        ...      ...        ...       ...            ...            ...   \n18201      711      0.0        0.0       1.0            1.0            0.0   \n18202      126      0.0        0.0       0.0            0.0            0.0   \n18203      650      1.0        0.0       0.0            0.0            0.0   \n18204      394      1.0        0.0       0.0            0.0            0.0   \n18205      547      0.0        1.0       0.0            0.0            0.0   \n\n       mean_embeddings_1  mean_embeddings_2  mean_embeddings_3  \\\n0               0.137180           0.073386           0.044837   \n1               0.038339           0.164428           0.153396   \n2              -0.022110           0.271280           0.067028   \n3              -0.121040           0.209104           0.160240   \n4              -0.078910           0.150048           0.249357   \n...                  ...                ...                ...   \n18201           0.031714           0.388612          -0.010097   \n18202          -0.012318           0.139221           0.027879   \n18203          -0.010492           0.312771          -0.006509   \n18204           0.142669           0.351709          -0.011775   \n18205           0.077811           0.190603           0.003248   \n\n       mean_embeddings_4  ...  mean_embeddings_1271  mean_embeddings_1272  \\\n0               0.036080  ...              0.380425             -0.079857   \n1               0.138865  ...              0.243933             -0.017564   \n2               0.057190  ...              0.249083             -0.091631   \n3               0.049583  ...              0.227777             -0.035011   \n4               0.005218  ...              0.313915             -0.165890   \n...                  ...  ...                   ...                   ...   \n18201           0.017263  ...              0.230494             -0.014877   \n18202           0.134511  ...              0.095944             -0.031087   \n18203          -0.017634  ...              0.131282             -0.077521   \n18204           0.057332  ...              0.239682              0.000409   \n18205          -0.014330  ...              0.243689             -0.052412   \n\n       mean_embeddings_1273  mean_embeddings_1274  mean_embeddings_1275  \\\n0                 -0.207201             -0.073626             -0.501474   \n1                 -0.265377             -0.022667             -0.370137   \n2                 -0.249087              0.040271             -0.415228   \n3                 -0.228398             -0.182060             -0.365424   \n4                 -0.182905             -0.105171             -0.435850   \n...                     ...                   ...                   ...   \n18201             -0.070507              0.092372             -0.097430   \n18202             -0.098680              0.103855             -1.264032   \n18203             -0.328603              0.149159             -0.601662   \n18204             -0.190628             -0.047931             -0.513402   \n18205             -0.022390              0.077389             -0.441519   \n\n       mean_embeddings_1276  mean_embeddings_1277  mean_embeddings_1278  \\\n0                  0.005484              0.040341             -0.137553   \n1                 -0.085303              0.096360             -0.074494   \n2                 -0.097675              0.179024              0.058127   \n3                  0.151473              0.101917             -0.043787   \n4                  0.146480              0.102739             -0.040836   \n...                     ...                   ...                   ...   \n18201              0.026271              0.038775              0.046432   \n18202             -0.091464              0.111977              0.028506   \n18203              0.151903              0.200224             -0.043059   \n18204              0.081698              0.118012             -0.053121   \n18205             -0.017692              0.086533              0.026601   \n\n       mean_embeddings_1279  mean_embeddings_1280  \n0                 -0.132132              0.009953  \n1                 -0.115237              0.163367  \n2                  0.004434              0.080192  \n3                 -0.066641              0.078485  \n4                 -0.302047             -0.037148  \n...                     ...                   ...  \n18201              0.007080             -0.010476  \n18202              0.110201              0.197081  \n18203             -0.091404             -0.073244  \n18204             -0.085886              0.228701  \n18205             -0.158437              0.124761  \n\n[18206 rows x 1286 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_len</th>\n      <th>Nucleus</th>\n      <th>Cytoplasm</th>\n      <th>Membrane</th>\n      <th>Cell membrane</th>\n      <th>Extracellular</th>\n      <th>mean_embeddings_1</th>\n      <th>mean_embeddings_2</th>\n      <th>mean_embeddings_3</th>\n      <th>mean_embeddings_4</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>306</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.137180</td>\n      <td>0.073386</td>\n      <td>0.044837</td>\n      <td>0.036080</td>\n      <td>...</td>\n      <td>0.380425</td>\n      <td>-0.079857</td>\n      <td>-0.207201</td>\n      <td>-0.073626</td>\n      <td>-0.501474</td>\n      <td>0.005484</td>\n      <td>0.040341</td>\n      <td>-0.137553</td>\n      <td>-0.132132</td>\n      <td>0.009953</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>951</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.038339</td>\n      <td>0.164428</td>\n      <td>0.153396</td>\n      <td>0.138865</td>\n      <td>...</td>\n      <td>0.243933</td>\n      <td>-0.017564</td>\n      <td>-0.265377</td>\n      <td>-0.022667</td>\n      <td>-0.370137</td>\n      <td>-0.085303</td>\n      <td>0.096360</td>\n      <td>-0.074494</td>\n      <td>-0.115237</td>\n      <td>0.163367</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>320</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>-0.022110</td>\n      <td>0.271280</td>\n      <td>0.067028</td>\n      <td>0.057190</td>\n      <td>...</td>\n      <td>0.249083</td>\n      <td>-0.091631</td>\n      <td>-0.249087</td>\n      <td>0.040271</td>\n      <td>-0.415228</td>\n      <td>-0.097675</td>\n      <td>0.179024</td>\n      <td>0.058127</td>\n      <td>0.004434</td>\n      <td>0.080192</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>520</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.121040</td>\n      <td>0.209104</td>\n      <td>0.160240</td>\n      <td>0.049583</td>\n      <td>...</td>\n      <td>0.227777</td>\n      <td>-0.035011</td>\n      <td>-0.228398</td>\n      <td>-0.182060</td>\n      <td>-0.365424</td>\n      <td>0.151473</td>\n      <td>0.101917</td>\n      <td>-0.043787</td>\n      <td>-0.066641</td>\n      <td>0.078485</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>782</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.078910</td>\n      <td>0.150048</td>\n      <td>0.249357</td>\n      <td>0.005218</td>\n      <td>...</td>\n      <td>0.313915</td>\n      <td>-0.165890</td>\n      <td>-0.182905</td>\n      <td>-0.105171</td>\n      <td>-0.435850</td>\n      <td>0.146480</td>\n      <td>0.102739</td>\n      <td>-0.040836</td>\n      <td>-0.302047</td>\n      <td>-0.037148</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18201</th>\n      <td>711</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.031714</td>\n      <td>0.388612</td>\n      <td>-0.010097</td>\n      <td>0.017263</td>\n      <td>...</td>\n      <td>0.230494</td>\n      <td>-0.014877</td>\n      <td>-0.070507</td>\n      <td>0.092372</td>\n      <td>-0.097430</td>\n      <td>0.026271</td>\n      <td>0.038775</td>\n      <td>0.046432</td>\n      <td>0.007080</td>\n      <td>-0.010476</td>\n    </tr>\n    <tr>\n      <th>18202</th>\n      <td>126</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.012318</td>\n      <td>0.139221</td>\n      <td>0.027879</td>\n      <td>0.134511</td>\n      <td>...</td>\n      <td>0.095944</td>\n      <td>-0.031087</td>\n      <td>-0.098680</td>\n      <td>0.103855</td>\n      <td>-1.264032</td>\n      <td>-0.091464</td>\n      <td>0.111977</td>\n      <td>0.028506</td>\n      <td>0.110201</td>\n      <td>0.197081</td>\n    </tr>\n    <tr>\n      <th>18203</th>\n      <td>650</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.010492</td>\n      <td>0.312771</td>\n      <td>-0.006509</td>\n      <td>-0.017634</td>\n      <td>...</td>\n      <td>0.131282</td>\n      <td>-0.077521</td>\n      <td>-0.328603</td>\n      <td>0.149159</td>\n      <td>-0.601662</td>\n      <td>0.151903</td>\n      <td>0.200224</td>\n      <td>-0.043059</td>\n      <td>-0.091404</td>\n      <td>-0.073244</td>\n    </tr>\n    <tr>\n      <th>18204</th>\n      <td>394</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.142669</td>\n      <td>0.351709</td>\n      <td>-0.011775</td>\n      <td>0.057332</td>\n      <td>...</td>\n      <td>0.239682</td>\n      <td>0.000409</td>\n      <td>-0.190628</td>\n      <td>-0.047931</td>\n      <td>-0.513402</td>\n      <td>0.081698</td>\n      <td>0.118012</td>\n      <td>-0.053121</td>\n      <td>-0.085886</td>\n      <td>0.228701</td>\n    </tr>\n    <tr>\n      <th>18205</th>\n      <td>547</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.077811</td>\n      <td>0.190603</td>\n      <td>0.003248</td>\n      <td>-0.014330</td>\n      <td>...</td>\n      <td>0.243689</td>\n      <td>-0.052412</td>\n      <td>-0.022390</td>\n      <td>0.077389</td>\n      <td>-0.441519</td>\n      <td>-0.017692</td>\n      <td>0.086533</td>\n      <td>0.026601</td>\n      <td>-0.158437</td>\n      <td>0.124761</td>\n    </tr>\n  </tbody>\n</table>\n<p>18206 rows × 1286 columns</p>\n</div>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y = data.iloc[:, 1:6]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"Nucleus\", \"Cytoplasm\", \"Membrane\", \"Cell membrane\", \"Extracellular\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "       seq_len  mean_embeddings_1  mean_embeddings_2  mean_embeddings_3  \\\n0          306           0.137180           0.073386           0.044837   \n1          951           0.038339           0.164428           0.153396   \n2          320          -0.022110           0.271280           0.067028   \n3          520          -0.121040           0.209104           0.160240   \n4          782          -0.078910           0.150048           0.249357   \n...        ...                ...                ...                ...   \n18201      711           0.031714           0.388612          -0.010097   \n18202      126          -0.012318           0.139221           0.027879   \n18203      650          -0.010492           0.312771          -0.006509   \n18204      394           0.142669           0.351709          -0.011775   \n18205      547           0.077811           0.190603           0.003248   \n\n       mean_embeddings_4  mean_embeddings_5  mean_embeddings_6  \\\n0               0.036080           0.016684          -0.092217   \n1               0.138865          -0.002554           0.002661   \n2               0.057190           0.018684          -0.030484   \n3               0.049583           0.073884          -0.156982   \n4               0.005218           0.028087          -0.105346   \n...                  ...                ...                ...   \n18201           0.017263          -0.047302          -0.117786   \n18202           0.134511          -0.032026          -0.146714   \n18203          -0.017634           0.033463          -0.145289   \n18204           0.057332           0.028234          -0.284333   \n18205          -0.014330          -0.041492          -0.039787   \n\n       mean_embeddings_7  mean_embeddings_8  mean_embeddings_9  ...  \\\n0              -0.397141          -0.134102          -0.284217  ...   \n1              -0.288359          -0.006911          -0.049193  ...   \n2              -0.005825          -0.028434          -0.245752  ...   \n3              -0.222404          -0.030891          -0.006564  ...   \n4              -0.262818           0.047545          -0.031606  ...   \n...                  ...                ...                ...  ...   \n18201          -0.229126           0.055318           0.007740  ...   \n18202          -0.082589           0.010380          -0.127913  ...   \n18203          -0.137043          -0.029649          -0.180368  ...   \n18204          -0.328261           0.125368          -0.262347  ...   \n18205          -0.129107          -0.043541          -0.101553  ...   \n\n       mean_embeddings_1271  mean_embeddings_1272  mean_embeddings_1273  \\\n0                  0.380425             -0.079857             -0.207201   \n1                  0.243933             -0.017564             -0.265377   \n2                  0.249083             -0.091631             -0.249087   \n3                  0.227777             -0.035011             -0.228398   \n4                  0.313915             -0.165890             -0.182905   \n...                     ...                   ...                   ...   \n18201              0.230494             -0.014877             -0.070507   \n18202              0.095944             -0.031087             -0.098680   \n18203              0.131282             -0.077521             -0.328603   \n18204              0.239682              0.000409             -0.190628   \n18205              0.243689             -0.052412             -0.022390   \n\n       mean_embeddings_1274  mean_embeddings_1275  mean_embeddings_1276  \\\n0                 -0.073626             -0.501474              0.005484   \n1                 -0.022667             -0.370137             -0.085303   \n2                  0.040271             -0.415228             -0.097675   \n3                 -0.182060             -0.365424              0.151473   \n4                 -0.105171             -0.435850              0.146480   \n...                     ...                   ...                   ...   \n18201              0.092372             -0.097430              0.026271   \n18202              0.103855             -1.264032             -0.091464   \n18203              0.149159             -0.601662              0.151903   \n18204             -0.047931             -0.513402              0.081698   \n18205              0.077389             -0.441519             -0.017692   \n\n       mean_embeddings_1277  mean_embeddings_1278  mean_embeddings_1279  \\\n0                  0.040341             -0.137553             -0.132132   \n1                  0.096360             -0.074494             -0.115237   \n2                  0.179024              0.058127              0.004434   \n3                  0.101917             -0.043787             -0.066641   \n4                  0.102739             -0.040836             -0.302047   \n...                     ...                   ...                   ...   \n18201              0.038775              0.046432              0.007080   \n18202              0.111977              0.028506              0.110201   \n18203              0.200224             -0.043059             -0.091404   \n18204              0.118012             -0.053121             -0.085886   \n18205              0.086533              0.026601             -0.158437   \n\n       mean_embeddings_1280  \n0                  0.009953  \n1                  0.163367  \n2                  0.080192  \n3                  0.078485  \n4                 -0.037148  \n...                     ...  \n18201             -0.010476  \n18202              0.197081  \n18203             -0.073244  \n18204              0.228701  \n18205              0.124761  \n\n[18206 rows x 1281 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_len</th>\n      <th>mean_embeddings_1</th>\n      <th>mean_embeddings_2</th>\n      <th>mean_embeddings_3</th>\n      <th>mean_embeddings_4</th>\n      <th>mean_embeddings_5</th>\n      <th>mean_embeddings_6</th>\n      <th>mean_embeddings_7</th>\n      <th>mean_embeddings_8</th>\n      <th>mean_embeddings_9</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>306</td>\n      <td>0.137180</td>\n      <td>0.073386</td>\n      <td>0.044837</td>\n      <td>0.036080</td>\n      <td>0.016684</td>\n      <td>-0.092217</td>\n      <td>-0.397141</td>\n      <td>-0.134102</td>\n      <td>-0.284217</td>\n      <td>...</td>\n      <td>0.380425</td>\n      <td>-0.079857</td>\n      <td>-0.207201</td>\n      <td>-0.073626</td>\n      <td>-0.501474</td>\n      <td>0.005484</td>\n      <td>0.040341</td>\n      <td>-0.137553</td>\n      <td>-0.132132</td>\n      <td>0.009953</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>951</td>\n      <td>0.038339</td>\n      <td>0.164428</td>\n      <td>0.153396</td>\n      <td>0.138865</td>\n      <td>-0.002554</td>\n      <td>0.002661</td>\n      <td>-0.288359</td>\n      <td>-0.006911</td>\n      <td>-0.049193</td>\n      <td>...</td>\n      <td>0.243933</td>\n      <td>-0.017564</td>\n      <td>-0.265377</td>\n      <td>-0.022667</td>\n      <td>-0.370137</td>\n      <td>-0.085303</td>\n      <td>0.096360</td>\n      <td>-0.074494</td>\n      <td>-0.115237</td>\n      <td>0.163367</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>320</td>\n      <td>-0.022110</td>\n      <td>0.271280</td>\n      <td>0.067028</td>\n      <td>0.057190</td>\n      <td>0.018684</td>\n      <td>-0.030484</td>\n      <td>-0.005825</td>\n      <td>-0.028434</td>\n      <td>-0.245752</td>\n      <td>...</td>\n      <td>0.249083</td>\n      <td>-0.091631</td>\n      <td>-0.249087</td>\n      <td>0.040271</td>\n      <td>-0.415228</td>\n      <td>-0.097675</td>\n      <td>0.179024</td>\n      <td>0.058127</td>\n      <td>0.004434</td>\n      <td>0.080192</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>520</td>\n      <td>-0.121040</td>\n      <td>0.209104</td>\n      <td>0.160240</td>\n      <td>0.049583</td>\n      <td>0.073884</td>\n      <td>-0.156982</td>\n      <td>-0.222404</td>\n      <td>-0.030891</td>\n      <td>-0.006564</td>\n      <td>...</td>\n      <td>0.227777</td>\n      <td>-0.035011</td>\n      <td>-0.228398</td>\n      <td>-0.182060</td>\n      <td>-0.365424</td>\n      <td>0.151473</td>\n      <td>0.101917</td>\n      <td>-0.043787</td>\n      <td>-0.066641</td>\n      <td>0.078485</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>782</td>\n      <td>-0.078910</td>\n      <td>0.150048</td>\n      <td>0.249357</td>\n      <td>0.005218</td>\n      <td>0.028087</td>\n      <td>-0.105346</td>\n      <td>-0.262818</td>\n      <td>0.047545</td>\n      <td>-0.031606</td>\n      <td>...</td>\n      <td>0.313915</td>\n      <td>-0.165890</td>\n      <td>-0.182905</td>\n      <td>-0.105171</td>\n      <td>-0.435850</td>\n      <td>0.146480</td>\n      <td>0.102739</td>\n      <td>-0.040836</td>\n      <td>-0.302047</td>\n      <td>-0.037148</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18201</th>\n      <td>711</td>\n      <td>0.031714</td>\n      <td>0.388612</td>\n      <td>-0.010097</td>\n      <td>0.017263</td>\n      <td>-0.047302</td>\n      <td>-0.117786</td>\n      <td>-0.229126</td>\n      <td>0.055318</td>\n      <td>0.007740</td>\n      <td>...</td>\n      <td>0.230494</td>\n      <td>-0.014877</td>\n      <td>-0.070507</td>\n      <td>0.092372</td>\n      <td>-0.097430</td>\n      <td>0.026271</td>\n      <td>0.038775</td>\n      <td>0.046432</td>\n      <td>0.007080</td>\n      <td>-0.010476</td>\n    </tr>\n    <tr>\n      <th>18202</th>\n      <td>126</td>\n      <td>-0.012318</td>\n      <td>0.139221</td>\n      <td>0.027879</td>\n      <td>0.134511</td>\n      <td>-0.032026</td>\n      <td>-0.146714</td>\n      <td>-0.082589</td>\n      <td>0.010380</td>\n      <td>-0.127913</td>\n      <td>...</td>\n      <td>0.095944</td>\n      <td>-0.031087</td>\n      <td>-0.098680</td>\n      <td>0.103855</td>\n      <td>-1.264032</td>\n      <td>-0.091464</td>\n      <td>0.111977</td>\n      <td>0.028506</td>\n      <td>0.110201</td>\n      <td>0.197081</td>\n    </tr>\n    <tr>\n      <th>18203</th>\n      <td>650</td>\n      <td>-0.010492</td>\n      <td>0.312771</td>\n      <td>-0.006509</td>\n      <td>-0.017634</td>\n      <td>0.033463</td>\n      <td>-0.145289</td>\n      <td>-0.137043</td>\n      <td>-0.029649</td>\n      <td>-0.180368</td>\n      <td>...</td>\n      <td>0.131282</td>\n      <td>-0.077521</td>\n      <td>-0.328603</td>\n      <td>0.149159</td>\n      <td>-0.601662</td>\n      <td>0.151903</td>\n      <td>0.200224</td>\n      <td>-0.043059</td>\n      <td>-0.091404</td>\n      <td>-0.073244</td>\n    </tr>\n    <tr>\n      <th>18204</th>\n      <td>394</td>\n      <td>0.142669</td>\n      <td>0.351709</td>\n      <td>-0.011775</td>\n      <td>0.057332</td>\n      <td>0.028234</td>\n      <td>-0.284333</td>\n      <td>-0.328261</td>\n      <td>0.125368</td>\n      <td>-0.262347</td>\n      <td>...</td>\n      <td>0.239682</td>\n      <td>0.000409</td>\n      <td>-0.190628</td>\n      <td>-0.047931</td>\n      <td>-0.513402</td>\n      <td>0.081698</td>\n      <td>0.118012</td>\n      <td>-0.053121</td>\n      <td>-0.085886</td>\n      <td>0.228701</td>\n    </tr>\n    <tr>\n      <th>18205</th>\n      <td>547</td>\n      <td>0.077811</td>\n      <td>0.190603</td>\n      <td>0.003248</td>\n      <td>-0.014330</td>\n      <td>-0.041492</td>\n      <td>-0.039787</td>\n      <td>-0.129107</td>\n      <td>-0.043541</td>\n      <td>-0.101553</td>\n      <td>...</td>\n      <td>0.243689</td>\n      <td>-0.052412</td>\n      <td>-0.022390</td>\n      <td>0.077389</td>\n      <td>-0.441519</td>\n      <td>-0.017692</td>\n      <td>0.086533</td>\n      <td>0.026601</td>\n      <td>-0.158437</td>\n      <td>0.124761</td>\n    </tr>\n  </tbody>\n</table>\n<p>18206 rows × 1281 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "       Nucleus  Cytoplasm  Membrane  Cell membrane  Extracellular\n0          1.0        1.0       0.0            0.0            0.0\n1          0.0        0.0       1.0            1.0            0.0\n2          0.0        1.0       1.0            1.0            0.0\n3          1.0        0.0       0.0            0.0            0.0\n4          0.0        0.0       0.0            0.0            0.0\n...        ...        ...       ...            ...            ...\n18201      0.0        0.0       1.0            1.0            0.0\n18202      0.0        0.0       0.0            0.0            0.0\n18203      1.0        0.0       0.0            0.0            0.0\n18204      1.0        0.0       0.0            0.0            0.0\n18205      0.0        1.0       0.0            0.0            0.0\n\n[18206 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Nucleus</th>\n      <th>Cytoplasm</th>\n      <th>Membrane</th>\n      <th>Cell membrane</th>\n      <th>Extracellular</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18201</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18202</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18203</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18204</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>18205</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>18206 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "y1 = y[\"Nucleus\"]\n",
    "y2 = y[\"Cytoplasm\"]\n",
    "y3 = y[\"Membrane\"]\n",
    "y4 = y[\"Cell membrane\"]\n",
    "y5 = y[\"Extracellular\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "            seq_len  mean_embeddings_1  mean_embeddings_2  mean_embeddings_3  \\\ncount  18206.000000       18206.000000       18206.000000       18206.000000   \nmean     478.705262           0.006390           0.207183           0.028280   \nstd      242.541811           0.075025           0.080888           0.088131   \nmin       40.000000          -0.380891          -0.137031          -0.388073   \n25%      279.000000          -0.041047           0.155868          -0.029339   \n50%      473.000000           0.009078           0.207592           0.028929   \n75%      648.000000           0.056207           0.259622           0.087662   \nmax     1022.000000           0.329307           0.526979           0.378263   \n\n       mean_embeddings_4  mean_embeddings_5  mean_embeddings_6  \\\ncount       18206.000000       18206.000000       18206.000000   \nmean            0.029587          -0.030373          -0.116181   \nstd             0.079767           0.085636           0.091158   \nmin            -0.343124          -0.463054          -0.706989   \n25%            -0.020575          -0.085322          -0.169363   \n50%             0.029206          -0.027265          -0.111160   \n75%             0.080486           0.027404          -0.056504   \nmax             0.480824           0.308735           0.252745   \n\n       mean_embeddings_7  mean_embeddings_8  mean_embeddings_9  ...  \\\ncount       18206.000000       18206.000000       18206.000000  ...   \nmean           -0.174446           0.054666          -0.107484  ...   \nstd             0.125308           0.120225           0.096616  ...   \nmin            -1.110152          -0.399615          -0.558280  ...   \n25%            -0.247207          -0.026115          -0.167882  ...   \n50%            -0.162604           0.043285          -0.104556  ...   \n75%            -0.087736           0.124576          -0.043513  ...   \nmax             0.290439           0.826020           0.296672  ...   \n\n       mean_embeddings_1271  mean_embeddings_1272  mean_embeddings_1273  \\\ncount          18206.000000          18206.000000          18206.000000   \nmean               0.211576             -0.040362             -0.143603   \nstd                0.103531              0.072538              0.086321   \nmin               -0.160231             -0.401173             -0.544120   \n25%                0.137063             -0.086831             -0.200474   \n50%                0.208782             -0.038182             -0.140635   \n75%                0.281331              0.008865             -0.084451   \nmax                0.730191              0.247426              0.230655   \n\n       mean_embeddings_1274  mean_embeddings_1275  mean_embeddings_1276  \\\ncount          18206.000000          18206.000000          18206.000000   \nmean               0.020231             -0.382939              0.046631   \nstd                0.096060              0.374074              0.091591   \nmin               -0.381301             -1.898537             -0.357362   \n25%               -0.041825             -0.630695             -0.015226   \n50%                0.025676             -0.352681              0.043129   \n75%                0.086999             -0.106689              0.106357   \nmax                0.404696              0.701578              0.461714   \n\n       mean_embeddings_1277  mean_embeddings_1278  mean_embeddings_1279  \\\ncount          18206.000000          18206.000000          18206.000000   \nmean               0.091950             -0.022884             -0.080571   \nstd                0.086122              0.087727              0.096320   \nmin               -0.261079             -0.477846             -0.433779   \n25%                0.034068             -0.077678             -0.145272   \n50%                0.090607             -0.022797             -0.082081   \n75%                0.147852              0.034122             -0.016331   \nmax                0.484299              0.429356              0.282278   \n\n       mean_embeddings_1280  \ncount          18206.000000  \nmean               0.077793  \nstd                0.114024  \nmin               -0.663165  \n25%                0.004353  \n50%                0.081184  \n75%                0.156294  \nmax                0.564578  \n\n[8 rows x 1281 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_len</th>\n      <th>mean_embeddings_1</th>\n      <th>mean_embeddings_2</th>\n      <th>mean_embeddings_3</th>\n      <th>mean_embeddings_4</th>\n      <th>mean_embeddings_5</th>\n      <th>mean_embeddings_6</th>\n      <th>mean_embeddings_7</th>\n      <th>mean_embeddings_8</th>\n      <th>mean_embeddings_9</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>...</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n      <td>18206.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>478.705262</td>\n      <td>0.006390</td>\n      <td>0.207183</td>\n      <td>0.028280</td>\n      <td>0.029587</td>\n      <td>-0.030373</td>\n      <td>-0.116181</td>\n      <td>-0.174446</td>\n      <td>0.054666</td>\n      <td>-0.107484</td>\n      <td>...</td>\n      <td>0.211576</td>\n      <td>-0.040362</td>\n      <td>-0.143603</td>\n      <td>0.020231</td>\n      <td>-0.382939</td>\n      <td>0.046631</td>\n      <td>0.091950</td>\n      <td>-0.022884</td>\n      <td>-0.080571</td>\n      <td>0.077793</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>242.541811</td>\n      <td>0.075025</td>\n      <td>0.080888</td>\n      <td>0.088131</td>\n      <td>0.079767</td>\n      <td>0.085636</td>\n      <td>0.091158</td>\n      <td>0.125308</td>\n      <td>0.120225</td>\n      <td>0.096616</td>\n      <td>...</td>\n      <td>0.103531</td>\n      <td>0.072538</td>\n      <td>0.086321</td>\n      <td>0.096060</td>\n      <td>0.374074</td>\n      <td>0.091591</td>\n      <td>0.086122</td>\n      <td>0.087727</td>\n      <td>0.096320</td>\n      <td>0.114024</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>40.000000</td>\n      <td>-0.380891</td>\n      <td>-0.137031</td>\n      <td>-0.388073</td>\n      <td>-0.343124</td>\n      <td>-0.463054</td>\n      <td>-0.706989</td>\n      <td>-1.110152</td>\n      <td>-0.399615</td>\n      <td>-0.558280</td>\n      <td>...</td>\n      <td>-0.160231</td>\n      <td>-0.401173</td>\n      <td>-0.544120</td>\n      <td>-0.381301</td>\n      <td>-1.898537</td>\n      <td>-0.357362</td>\n      <td>-0.261079</td>\n      <td>-0.477846</td>\n      <td>-0.433779</td>\n      <td>-0.663165</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>279.000000</td>\n      <td>-0.041047</td>\n      <td>0.155868</td>\n      <td>-0.029339</td>\n      <td>-0.020575</td>\n      <td>-0.085322</td>\n      <td>-0.169363</td>\n      <td>-0.247207</td>\n      <td>-0.026115</td>\n      <td>-0.167882</td>\n      <td>...</td>\n      <td>0.137063</td>\n      <td>-0.086831</td>\n      <td>-0.200474</td>\n      <td>-0.041825</td>\n      <td>-0.630695</td>\n      <td>-0.015226</td>\n      <td>0.034068</td>\n      <td>-0.077678</td>\n      <td>-0.145272</td>\n      <td>0.004353</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>473.000000</td>\n      <td>0.009078</td>\n      <td>0.207592</td>\n      <td>0.028929</td>\n      <td>0.029206</td>\n      <td>-0.027265</td>\n      <td>-0.111160</td>\n      <td>-0.162604</td>\n      <td>0.043285</td>\n      <td>-0.104556</td>\n      <td>...</td>\n      <td>0.208782</td>\n      <td>-0.038182</td>\n      <td>-0.140635</td>\n      <td>0.025676</td>\n      <td>-0.352681</td>\n      <td>0.043129</td>\n      <td>0.090607</td>\n      <td>-0.022797</td>\n      <td>-0.082081</td>\n      <td>0.081184</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>648.000000</td>\n      <td>0.056207</td>\n      <td>0.259622</td>\n      <td>0.087662</td>\n      <td>0.080486</td>\n      <td>0.027404</td>\n      <td>-0.056504</td>\n      <td>-0.087736</td>\n      <td>0.124576</td>\n      <td>-0.043513</td>\n      <td>...</td>\n      <td>0.281331</td>\n      <td>0.008865</td>\n      <td>-0.084451</td>\n      <td>0.086999</td>\n      <td>-0.106689</td>\n      <td>0.106357</td>\n      <td>0.147852</td>\n      <td>0.034122</td>\n      <td>-0.016331</td>\n      <td>0.156294</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1022.000000</td>\n      <td>0.329307</td>\n      <td>0.526979</td>\n      <td>0.378263</td>\n      <td>0.480824</td>\n      <td>0.308735</td>\n      <td>0.252745</td>\n      <td>0.290439</td>\n      <td>0.826020</td>\n      <td>0.296672</td>\n      <td>...</td>\n      <td>0.730191</td>\n      <td>0.247426</td>\n      <td>0.230655</td>\n      <td>0.404696</td>\n      <td>0.701578</td>\n      <td>0.461714</td>\n      <td>0.484299</td>\n      <td>0.429356</td>\n      <td>0.282278</td>\n      <td>0.564578</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 1281 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "0        1.0\n1        0.0\n2        0.0\n3        1.0\n4        0.0\n        ... \n18201    0.0\n18202    0.0\n18203    1.0\n18204    1.0\n18205    0.0\nName: Nucleus, Length: 18206, dtype: float64"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohamed/anaconda3/envs/ai2e/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n                   warm_start=False)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg1 = LogisticRegression(max_iter=100)\n",
    "log_reg1.fit(X.drop(columns=[\"seq_len\"]), y1.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "0        1.0\n1        0.0\n2        0.0\n3        1.0\n4        0.0\n        ... \n18201    0.0\n18202    0.0\n18203    1.0\n18204    1.0\n18205    0.0\nName: Nucleus, Length: 18206, dtype: float64"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "       seq_len  mean_embeddings_1  mean_embeddings_2  mean_embeddings_3  \\\n0          306           0.137180           0.073386           0.044837   \n1          951           0.038339           0.164428           0.153396   \n2          320          -0.022110           0.271280           0.067028   \n3          520          -0.121040           0.209104           0.160240   \n4          782          -0.078910           0.150048           0.249357   \n...        ...                ...                ...                ...   \n18201      711           0.031714           0.388612          -0.010097   \n18202      126          -0.012318           0.139221           0.027879   \n18203      650          -0.010492           0.312771          -0.006509   \n18204      394           0.142669           0.351709          -0.011775   \n18205      547           0.077811           0.190603           0.003248   \n\n       mean_embeddings_4  mean_embeddings_5  mean_embeddings_6  \\\n0               0.036080           0.016684          -0.092217   \n1               0.138865          -0.002554           0.002661   \n2               0.057190           0.018684          -0.030484   \n3               0.049583           0.073884          -0.156982   \n4               0.005218           0.028087          -0.105346   \n...                  ...                ...                ...   \n18201           0.017263          -0.047302          -0.117786   \n18202           0.134511          -0.032026          -0.146714   \n18203          -0.017634           0.033463          -0.145289   \n18204           0.057332           0.028234          -0.284333   \n18205          -0.014330          -0.041492          -0.039787   \n\n       mean_embeddings_7  mean_embeddings_8  mean_embeddings_9  ...  \\\n0              -0.397141          -0.134102          -0.284217  ...   \n1              -0.288359          -0.006911          -0.049193  ...   \n2              -0.005825          -0.028434          -0.245752  ...   \n3              -0.222404          -0.030891          -0.006564  ...   \n4              -0.262818           0.047545          -0.031606  ...   \n...                  ...                ...                ...  ...   \n18201          -0.229126           0.055318           0.007740  ...   \n18202          -0.082589           0.010380          -0.127913  ...   \n18203          -0.137043          -0.029649          -0.180368  ...   \n18204          -0.328261           0.125368          -0.262347  ...   \n18205          -0.129107          -0.043541          -0.101553  ...   \n\n       mean_embeddings_1271  mean_embeddings_1272  mean_embeddings_1273  \\\n0                  0.380425             -0.079857             -0.207201   \n1                  0.243933             -0.017564             -0.265377   \n2                  0.249083             -0.091631             -0.249087   \n3                  0.227777             -0.035011             -0.228398   \n4                  0.313915             -0.165890             -0.182905   \n...                     ...                   ...                   ...   \n18201              0.230494             -0.014877             -0.070507   \n18202              0.095944             -0.031087             -0.098680   \n18203              0.131282             -0.077521             -0.328603   \n18204              0.239682              0.000409             -0.190628   \n18205              0.243689             -0.052412             -0.022390   \n\n       mean_embeddings_1274  mean_embeddings_1275  mean_embeddings_1276  \\\n0                 -0.073626             -0.501474              0.005484   \n1                 -0.022667             -0.370137             -0.085303   \n2                  0.040271             -0.415228             -0.097675   \n3                 -0.182060             -0.365424              0.151473   \n4                 -0.105171             -0.435850              0.146480   \n...                     ...                   ...                   ...   \n18201              0.092372             -0.097430              0.026271   \n18202              0.103855             -1.264032             -0.091464   \n18203              0.149159             -0.601662              0.151903   \n18204             -0.047931             -0.513402              0.081698   \n18205              0.077389             -0.441519             -0.017692   \n\n       mean_embeddings_1277  mean_embeddings_1278  mean_embeddings_1279  \\\n0                  0.040341             -0.137553             -0.132132   \n1                  0.096360             -0.074494             -0.115237   \n2                  0.179024              0.058127              0.004434   \n3                  0.101917             -0.043787             -0.066641   \n4                  0.102739             -0.040836             -0.302047   \n...                     ...                   ...                   ...   \n18201              0.038775              0.046432              0.007080   \n18202              0.111977              0.028506              0.110201   \n18203              0.200224             -0.043059             -0.091404   \n18204              0.118012             -0.053121             -0.085886   \n18205              0.086533              0.026601             -0.158437   \n\n       mean_embeddings_1280  \n0                  0.009953  \n1                  0.163367  \n2                  0.080192  \n3                  0.078485  \n4                 -0.037148  \n...                     ...  \n18201             -0.010476  \n18202              0.197081  \n18203             -0.073244  \n18204              0.228701  \n18205              0.124761  \n\n[18206 rows x 1281 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_len</th>\n      <th>mean_embeddings_1</th>\n      <th>mean_embeddings_2</th>\n      <th>mean_embeddings_3</th>\n      <th>mean_embeddings_4</th>\n      <th>mean_embeddings_5</th>\n      <th>mean_embeddings_6</th>\n      <th>mean_embeddings_7</th>\n      <th>mean_embeddings_8</th>\n      <th>mean_embeddings_9</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>306</td>\n      <td>0.137180</td>\n      <td>0.073386</td>\n      <td>0.044837</td>\n      <td>0.036080</td>\n      <td>0.016684</td>\n      <td>-0.092217</td>\n      <td>-0.397141</td>\n      <td>-0.134102</td>\n      <td>-0.284217</td>\n      <td>...</td>\n      <td>0.380425</td>\n      <td>-0.079857</td>\n      <td>-0.207201</td>\n      <td>-0.073626</td>\n      <td>-0.501474</td>\n      <td>0.005484</td>\n      <td>0.040341</td>\n      <td>-0.137553</td>\n      <td>-0.132132</td>\n      <td>0.009953</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>951</td>\n      <td>0.038339</td>\n      <td>0.164428</td>\n      <td>0.153396</td>\n      <td>0.138865</td>\n      <td>-0.002554</td>\n      <td>0.002661</td>\n      <td>-0.288359</td>\n      <td>-0.006911</td>\n      <td>-0.049193</td>\n      <td>...</td>\n      <td>0.243933</td>\n      <td>-0.017564</td>\n      <td>-0.265377</td>\n      <td>-0.022667</td>\n      <td>-0.370137</td>\n      <td>-0.085303</td>\n      <td>0.096360</td>\n      <td>-0.074494</td>\n      <td>-0.115237</td>\n      <td>0.163367</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>320</td>\n      <td>-0.022110</td>\n      <td>0.271280</td>\n      <td>0.067028</td>\n      <td>0.057190</td>\n      <td>0.018684</td>\n      <td>-0.030484</td>\n      <td>-0.005825</td>\n      <td>-0.028434</td>\n      <td>-0.245752</td>\n      <td>...</td>\n      <td>0.249083</td>\n      <td>-0.091631</td>\n      <td>-0.249087</td>\n      <td>0.040271</td>\n      <td>-0.415228</td>\n      <td>-0.097675</td>\n      <td>0.179024</td>\n      <td>0.058127</td>\n      <td>0.004434</td>\n      <td>0.080192</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>520</td>\n      <td>-0.121040</td>\n      <td>0.209104</td>\n      <td>0.160240</td>\n      <td>0.049583</td>\n      <td>0.073884</td>\n      <td>-0.156982</td>\n      <td>-0.222404</td>\n      <td>-0.030891</td>\n      <td>-0.006564</td>\n      <td>...</td>\n      <td>0.227777</td>\n      <td>-0.035011</td>\n      <td>-0.228398</td>\n      <td>-0.182060</td>\n      <td>-0.365424</td>\n      <td>0.151473</td>\n      <td>0.101917</td>\n      <td>-0.043787</td>\n      <td>-0.066641</td>\n      <td>0.078485</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>782</td>\n      <td>-0.078910</td>\n      <td>0.150048</td>\n      <td>0.249357</td>\n      <td>0.005218</td>\n      <td>0.028087</td>\n      <td>-0.105346</td>\n      <td>-0.262818</td>\n      <td>0.047545</td>\n      <td>-0.031606</td>\n      <td>...</td>\n      <td>0.313915</td>\n      <td>-0.165890</td>\n      <td>-0.182905</td>\n      <td>-0.105171</td>\n      <td>-0.435850</td>\n      <td>0.146480</td>\n      <td>0.102739</td>\n      <td>-0.040836</td>\n      <td>-0.302047</td>\n      <td>-0.037148</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18201</th>\n      <td>711</td>\n      <td>0.031714</td>\n      <td>0.388612</td>\n      <td>-0.010097</td>\n      <td>0.017263</td>\n      <td>-0.047302</td>\n      <td>-0.117786</td>\n      <td>-0.229126</td>\n      <td>0.055318</td>\n      <td>0.007740</td>\n      <td>...</td>\n      <td>0.230494</td>\n      <td>-0.014877</td>\n      <td>-0.070507</td>\n      <td>0.092372</td>\n      <td>-0.097430</td>\n      <td>0.026271</td>\n      <td>0.038775</td>\n      <td>0.046432</td>\n      <td>0.007080</td>\n      <td>-0.010476</td>\n    </tr>\n    <tr>\n      <th>18202</th>\n      <td>126</td>\n      <td>-0.012318</td>\n      <td>0.139221</td>\n      <td>0.027879</td>\n      <td>0.134511</td>\n      <td>-0.032026</td>\n      <td>-0.146714</td>\n      <td>-0.082589</td>\n      <td>0.010380</td>\n      <td>-0.127913</td>\n      <td>...</td>\n      <td>0.095944</td>\n      <td>-0.031087</td>\n      <td>-0.098680</td>\n      <td>0.103855</td>\n      <td>-1.264032</td>\n      <td>-0.091464</td>\n      <td>0.111977</td>\n      <td>0.028506</td>\n      <td>0.110201</td>\n      <td>0.197081</td>\n    </tr>\n    <tr>\n      <th>18203</th>\n      <td>650</td>\n      <td>-0.010492</td>\n      <td>0.312771</td>\n      <td>-0.006509</td>\n      <td>-0.017634</td>\n      <td>0.033463</td>\n      <td>-0.145289</td>\n      <td>-0.137043</td>\n      <td>-0.029649</td>\n      <td>-0.180368</td>\n      <td>...</td>\n      <td>0.131282</td>\n      <td>-0.077521</td>\n      <td>-0.328603</td>\n      <td>0.149159</td>\n      <td>-0.601662</td>\n      <td>0.151903</td>\n      <td>0.200224</td>\n      <td>-0.043059</td>\n      <td>-0.091404</td>\n      <td>-0.073244</td>\n    </tr>\n    <tr>\n      <th>18204</th>\n      <td>394</td>\n      <td>0.142669</td>\n      <td>0.351709</td>\n      <td>-0.011775</td>\n      <td>0.057332</td>\n      <td>0.028234</td>\n      <td>-0.284333</td>\n      <td>-0.328261</td>\n      <td>0.125368</td>\n      <td>-0.262347</td>\n      <td>...</td>\n      <td>0.239682</td>\n      <td>0.000409</td>\n      <td>-0.190628</td>\n      <td>-0.047931</td>\n      <td>-0.513402</td>\n      <td>0.081698</td>\n      <td>0.118012</td>\n      <td>-0.053121</td>\n      <td>-0.085886</td>\n      <td>0.228701</td>\n    </tr>\n    <tr>\n      <th>18205</th>\n      <td>547</td>\n      <td>0.077811</td>\n      <td>0.190603</td>\n      <td>0.003248</td>\n      <td>-0.014330</td>\n      <td>-0.041492</td>\n      <td>-0.039787</td>\n      <td>-0.129107</td>\n      <td>-0.043541</td>\n      <td>-0.101553</td>\n      <td>...</td>\n      <td>0.243689</td>\n      <td>-0.052412</td>\n      <td>-0.022390</td>\n      <td>0.077389</td>\n      <td>-0.441519</td>\n      <td>-0.017692</td>\n      <td>0.086533</td>\n      <td>0.026601</td>\n      <td>-0.158437</td>\n      <td>0.124761</td>\n    </tr>\n  </tbody>\n</table>\n<p>18206 rows × 1281 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "trees = RandomForestClassifier()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=None, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees.fit(X, y1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "del trees\n",
    "del log_reg1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.4856 - acc: 0.7861\n",
      "Epoch 2/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.4001 - acc: 0.8242\n",
      "Epoch 3/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3809 - acc: 0.8310\n",
      "Epoch 4/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3602 - acc: 0.8426\n",
      "Epoch 5/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3425 - acc: 0.8502\n",
      "Epoch 6/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3473 - acc: 0.8471\n",
      "Epoch 7/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3344 - acc: 0.8535\n",
      "Epoch 8/20\n",
      "569/569 [==============================] - 1s 2ms/step - loss: 0.3345 - acc: 0.8517\n",
      "Epoch 9/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3418 - acc: 0.8491\n",
      "Epoch 10/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3275 - acc: 0.8560\n",
      "Epoch 11/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3265 - acc: 0.8588\n",
      "Epoch 12/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3219 - acc: 0.8594\n",
      "Epoch 13/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3176 - acc: 0.8617\n",
      "Epoch 14/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3185 - acc: 0.8604\n",
      "Epoch 15/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3224 - acc: 0.8596\n",
      "Epoch 16/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3150 - acc: 0.8624\n",
      "Epoch 17/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3158 - acc: 0.8642\n",
      "Epoch 18/20\n",
      "569/569 [==============================] - 1s 972us/step - loss: 0.3110 - acc: 0.8656\n",
      "Epoch 19/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3151 - acc: 0.8644\n",
      "Epoch 20/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3108 - acc: 0.8648\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fef60249110>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X.to_numpy(), y1.to_numpy(), epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 3.06000000e+02,  1.37179960e-01,  7.33856700e-02, ...,\n        -1.37553200e-01, -1.32132380e-01,  9.95330400e-03],\n       [ 9.51000000e+02,  3.83386160e-02,  1.64428040e-01, ...,\n        -7.44936600e-02, -1.15236536e-01,  1.63366810e-01],\n       [ 3.20000000e+02, -2.21100520e-02,  2.71280200e-01, ...,\n         5.81270400e-02,  4.43439500e-03,  8.01921200e-02],\n       ...,\n       [ 6.50000000e+02, -1.04915030e-02,  3.12771020e-01, ...,\n        -4.30590320e-02, -9.14036400e-02, -7.32437700e-02],\n       [ 3.94000000e+02,  1.42669410e-01,  3.51709040e-01, ...,\n        -5.31213200e-02, -8.58858700e-02,  2.28701140e-01],\n       [ 5.47000000e+02,  7.78113750e-02,  1.90602990e-01, ...,\n         2.66011380e-02, -1.58436780e-01,  1.24760516e-01]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.4767 - acc: 0.8139\n",
      "Epoch 2/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3733 - acc: 0.8518\n",
      "Epoch 3/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3567 - acc: 0.8568\n",
      "Epoch 4/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3396 - acc: 0.8595\n",
      "Epoch 5/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3178 - acc: 0.8703\n",
      "Epoch 6/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3086 - acc: 0.8723\n",
      "Epoch 7/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3149 - acc: 0.8733\n",
      "Epoch 8/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3044 - acc: 0.8768\n",
      "Epoch 9/20\n",
      "569/569 [==============================] - 1s 899us/step - loss: 0.3054 - acc: 0.8757\n",
      "Epoch 10/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3007 - acc: 0.8784\n",
      "Epoch 11/20\n",
      "569/569 [==============================] - 1s 998us/step - loss: 0.2982 - acc: 0.8800\n",
      "Epoch 12/20\n",
      "569/569 [==============================] - 1s 995us/step - loss: 0.3035 - acc: 0.8758\n",
      "Epoch 13/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2945 - acc: 0.8810\n",
      "Epoch 14/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2914 - acc: 0.8826\n",
      "Epoch 15/20\n",
      "569/569 [==============================] - 1s 976us/step - loss: 0.2909 - acc: 0.8835\n",
      "Epoch 16/20\n",
      "569/569 [==============================] - 1s 971us/step - loss: 0.2924 - acc: 0.8810\n",
      "Epoch 17/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2935 - acc: 0.8801\n",
      "Epoch 18/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2864 - acc: 0.8815\n",
      "Epoch 19/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2916 - acc: 0.8819\n",
      "Epoch 20/20\n",
      "569/569 [==============================] - 1s 2ms/step - loss: 0.2911 - acc: 0.8820\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fef5863a390>"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model2.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model2.fit(X.to_numpy(), y2.to_numpy(), epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.3501 - acc: 0.8787\n",
      "Epoch 2/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2693 - acc: 0.8992\n",
      "Epoch 3/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2500 - acc: 0.9049\n",
      "Epoch 4/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2499 - acc: 0.9067\n",
      "Epoch 5/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2297 - acc: 0.9131\n",
      "Epoch 6/20\n",
      "569/569 [==============================] - 1s 2ms/step - loss: 0.2290 - acc: 0.9115\n",
      "Epoch 7/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2417 - acc: 0.9092\n",
      "Epoch 8/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2167 - acc: 0.9166\n",
      "Epoch 9/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2127 - acc: 0.9183\n",
      "Epoch 10/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2108 - acc: 0.9177\n",
      "Epoch 11/20\n",
      "569/569 [==============================] - 1s 998us/step - loss: 0.2138 - acc: 0.9162\n",
      "Epoch 12/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2080 - acc: 0.9187\n",
      "Epoch 13/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2114 - acc: 0.9184\n",
      "Epoch 14/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2056 - acc: 0.9211\n",
      "Epoch 15/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2074 - acc: 0.9211\n",
      "Epoch 16/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2032 - acc: 0.9216\n",
      "Epoch 17/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2028 - acc: 0.9233\n",
      "Epoch 18/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2037 - acc: 0.9210\n",
      "Epoch 19/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.2022 - acc: 0.9209\n",
      "Epoch 20/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.1997 - acc: 0.9224\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fef582d2390>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model3.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model3.fit(X.to_numpy(), y3.to_numpy(), epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.1732 - acc: 0.9504\n",
      "Epoch 2/20\n",
      "569/569 [==============================] - 1s 2ms/step - loss: 0.1217 - acc: 0.9612\n",
      "Epoch 3/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.1177 - acc: 0.9634\n",
      "Epoch 4/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0978 - acc: 0.9659\n",
      "Epoch 5/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0966 - acc: 0.9659\n",
      "Epoch 6/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0937 - acc: 0.9691\n",
      "Epoch 7/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0878 - acc: 0.9697\n",
      "Epoch 8/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0828 - acc: 0.9714\n",
      "Epoch 9/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0913 - acc: 0.9690\n",
      "Epoch 10/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0849 - acc: 0.9708\n",
      "Epoch 11/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0784 - acc: 0.9725\n",
      "Epoch 12/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0833 - acc: 0.9699\n",
      "Epoch 13/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0795 - acc: 0.9733\n",
      "Epoch 14/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0754 - acc: 0.9745\n",
      "Epoch 15/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0803 - acc: 0.9715\n",
      "Epoch 16/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0780 - acc: 0.9734\n",
      "Epoch 17/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0774 - acc: 0.9737\n",
      "Epoch 18/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0761 - acc: 0.9734\n",
      "Epoch 19/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0759 - acc: 0.9740\n",
      "Epoch 20/20\n",
      "569/569 [==============================] - 1s 1ms/step - loss: 0.0736 - acc: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fef5071c1d0>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model4.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model4.fit(X.to_numpy(), y4.to_numpy(), epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model5 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model5.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model5.fit(X.to_numpy(), y5.to_numpy(), epochs=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "test_data = test_df.merge(mean_embeddings_df, left_on='sequence', right_on='sequence')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "             ID                                           sequence  \\\n0        test_0  MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...   \n1        test_1  MAAAAAAAAATNGTGGSSGMEVDAAVVPSVMACGVTGSVSVALHPL...   \n2        test_2  MAAAAAAAGGAALAVSTGLETATLQKLALRRKKVLGAEEMELYELA...   \n3        test_3  MAAAAAAGPEMVRGQVFDVGPRYTNLSYIGEGAYGMVCSAYDNLNK...   \n4        test_4  MAAAAAETPEVLRECGCKGIRTCLICERQRGSDPPWELPPAKTYRF...   \n...         ...                                                ...   \n6483  test_6483  MYTLYILSLLCAFVTFSECKYPPGPIYPHRPIYPIQPVYPDHCPGV...   \n6484  test_6484  MYVSNGKDTCQLLGPVSLFVQTLMGMTAVIVLLVKRNYEHPRRKMI...   \n6485  test_6485  MYVWPCAVVLAQYLWFHRRSLPGKAILEIGAGVSLPGILAAKCGAE...   \n6486  test_6486  MYYHNQHQGKSILSSSRMPISSERHPFLRGNGTGDSGLILSTDAKP...   \n6487  test_6487  MYYIGHPSYYRKHIEHVCFQHSGILKKRNYQKNQKKYIMKLNESAM...   \n\n            Kingdom  seq_len  mean_embeddings_1  mean_embeddings_2  \\\n0           Metazoa      306           0.138000           0.078087   \n1           Metazoa      327          -0.051710           0.353796   \n2           Metazoa      159          -0.002891           0.152937   \n3           Metazoa      358          -0.091884           0.188601   \n4           Metazoa      302          -0.138956           0.168996   \n...             ...      ...                ...                ...   \n6483        Metazoa      138          -0.081279           0.184097   \n6484          Fungi      273           0.045067           0.240210   \n6485        Metazoa      190          -0.080344           0.316687   \n6486  Viridiplantae      402           0.127888           0.349859   \n6487          Fungi      464           0.030072           0.241007   \n\n      mean_embeddings_3  mean_embeddings_4  mean_embeddings_5  \\\n0              0.048324           0.035530           0.013417   \n1              0.149786          -0.109090           0.012032   \n2              0.173129           0.075425           0.024429   \n3              0.056167           0.081018          -0.026512   \n4              0.114288          -0.081320           0.028298   \n...                 ...                ...                ...   \n6483          -0.011704           0.120396           0.008164   \n6484           0.010367           0.108304          -0.067205   \n6485          -0.070094          -0.051003          -0.046601   \n6486           0.000780           0.060009           0.036233   \n6487          -0.088931           0.090009          -0.036844   \n\n      mean_embeddings_6  ...  mean_embeddings_1271  mean_embeddings_1272  \\\n0             -0.096783  ...              0.383642             -0.084738   \n1             -0.096914  ...              0.402158             -0.074534   \n2             -0.159387  ...              0.250508              0.014100   \n3             -0.300105  ...              0.171207             -0.241675   \n4              0.004822  ...              0.482548             -0.155571   \n...                 ...  ...                   ...                   ...   \n6483          -0.088014  ...              0.087244             -0.027435   \n6484          -0.121369  ...              0.088721              0.016557   \n6485          -0.147084  ...              0.466889             -0.217825   \n6486          -0.261401  ...              0.217066              0.015657   \n6487          -0.013518  ...              0.272390             -0.045815   \n\n      mean_embeddings_1273  mean_embeddings_1274  mean_embeddings_1275  \\\n0                -0.215819             -0.065172             -0.514831   \n1                -0.124143              0.052344             -0.414115   \n2                -0.208263              0.034511             -0.681030   \n3                -0.362721             -0.036837              0.262394   \n4                -0.209955              0.011263             -0.416560   \n...                    ...                   ...                   ...   \n6483             -0.153783             -0.108225             -0.276514   \n6484             -0.171101              0.151766             -0.244892   \n6485             -0.149523             -0.105499              0.234158   \n6486             -0.191005             -0.040256             -0.503746   \n6487             -0.004871             -0.012933             -0.179958   \n\n      mean_embeddings_1276  mean_embeddings_1277  mean_embeddings_1278  \\\n0                 0.005591              0.045531             -0.137004   \n1                 0.131673              0.130051             -0.029759   \n2                -0.005970              0.219935             -0.058027   \n3                 0.242967              0.107660             -0.192324   \n4                 0.123376              0.061400              0.007495   \n...                    ...                   ...                   ...   \n6483             -0.072615              0.066795              0.120175   \n6484              0.108346              0.181892              0.037327   \n6485              0.122640              0.242110             -0.011383   \n6486              0.049176              0.112414             -0.062682   \n6487             -0.076372              0.001504              0.009703   \n\n      mean_embeddings_1279  mean_embeddings_1280  \n0                -0.135382              0.012397  \n1                -0.169029              0.024629  \n2                -0.035240              0.027064  \n3                -0.115085              0.064569  \n4                -0.038448             -0.025895  \n...                    ...                   ...  \n6483             -0.014717              0.094264  \n6484              0.023023              0.076660  \n6485             -0.079558             -0.202546  \n6486             -0.050713              0.236100  \n6487              0.001611              0.047157  \n\n[6488 rows x 1284 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>sequence</th>\n      <th>Kingdom</th>\n      <th>seq_len</th>\n      <th>mean_embeddings_1</th>\n      <th>mean_embeddings_2</th>\n      <th>mean_embeddings_3</th>\n      <th>mean_embeddings_4</th>\n      <th>mean_embeddings_5</th>\n      <th>mean_embeddings_6</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>test_0</td>\n      <td>MAAAAAAAAAAGAAGGRGSGPGRRRHLVPGAGGEAGEGAPGGAGDY...</td>\n      <td>Metazoa</td>\n      <td>306</td>\n      <td>0.138000</td>\n      <td>0.078087</td>\n      <td>0.048324</td>\n      <td>0.035530</td>\n      <td>0.013417</td>\n      <td>-0.096783</td>\n      <td>...</td>\n      <td>0.383642</td>\n      <td>-0.084738</td>\n      <td>-0.215819</td>\n      <td>-0.065172</td>\n      <td>-0.514831</td>\n      <td>0.005591</td>\n      <td>0.045531</td>\n      <td>-0.137004</td>\n      <td>-0.135382</td>\n      <td>0.012397</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>test_1</td>\n      <td>MAAAAAAAAATNGTGGSSGMEVDAAVVPSVMACGVTGSVSVALHPL...</td>\n      <td>Metazoa</td>\n      <td>327</td>\n      <td>-0.051710</td>\n      <td>0.353796</td>\n      <td>0.149786</td>\n      <td>-0.109090</td>\n      <td>0.012032</td>\n      <td>-0.096914</td>\n      <td>...</td>\n      <td>0.402158</td>\n      <td>-0.074534</td>\n      <td>-0.124143</td>\n      <td>0.052344</td>\n      <td>-0.414115</td>\n      <td>0.131673</td>\n      <td>0.130051</td>\n      <td>-0.029759</td>\n      <td>-0.169029</td>\n      <td>0.024629</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>test_2</td>\n      <td>MAAAAAAAGGAALAVSTGLETATLQKLALRRKKVLGAEEMELYELA...</td>\n      <td>Metazoa</td>\n      <td>159</td>\n      <td>-0.002891</td>\n      <td>0.152937</td>\n      <td>0.173129</td>\n      <td>0.075425</td>\n      <td>0.024429</td>\n      <td>-0.159387</td>\n      <td>...</td>\n      <td>0.250508</td>\n      <td>0.014100</td>\n      <td>-0.208263</td>\n      <td>0.034511</td>\n      <td>-0.681030</td>\n      <td>-0.005970</td>\n      <td>0.219935</td>\n      <td>-0.058027</td>\n      <td>-0.035240</td>\n      <td>0.027064</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>test_3</td>\n      <td>MAAAAAAGPEMVRGQVFDVGPRYTNLSYIGEGAYGMVCSAYDNLNK...</td>\n      <td>Metazoa</td>\n      <td>358</td>\n      <td>-0.091884</td>\n      <td>0.188601</td>\n      <td>0.056167</td>\n      <td>0.081018</td>\n      <td>-0.026512</td>\n      <td>-0.300105</td>\n      <td>...</td>\n      <td>0.171207</td>\n      <td>-0.241675</td>\n      <td>-0.362721</td>\n      <td>-0.036837</td>\n      <td>0.262394</td>\n      <td>0.242967</td>\n      <td>0.107660</td>\n      <td>-0.192324</td>\n      <td>-0.115085</td>\n      <td>0.064569</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>test_4</td>\n      <td>MAAAAAETPEVLRECGCKGIRTCLICERQRGSDPPWELPPAKTYRF...</td>\n      <td>Metazoa</td>\n      <td>302</td>\n      <td>-0.138956</td>\n      <td>0.168996</td>\n      <td>0.114288</td>\n      <td>-0.081320</td>\n      <td>0.028298</td>\n      <td>0.004822</td>\n      <td>...</td>\n      <td>0.482548</td>\n      <td>-0.155571</td>\n      <td>-0.209955</td>\n      <td>0.011263</td>\n      <td>-0.416560</td>\n      <td>0.123376</td>\n      <td>0.061400</td>\n      <td>0.007495</td>\n      <td>-0.038448</td>\n      <td>-0.025895</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6483</th>\n      <td>test_6483</td>\n      <td>MYTLYILSLLCAFVTFSECKYPPGPIYPHRPIYPIQPVYPDHCPGV...</td>\n      <td>Metazoa</td>\n      <td>138</td>\n      <td>-0.081279</td>\n      <td>0.184097</td>\n      <td>-0.011704</td>\n      <td>0.120396</td>\n      <td>0.008164</td>\n      <td>-0.088014</td>\n      <td>...</td>\n      <td>0.087244</td>\n      <td>-0.027435</td>\n      <td>-0.153783</td>\n      <td>-0.108225</td>\n      <td>-0.276514</td>\n      <td>-0.072615</td>\n      <td>0.066795</td>\n      <td>0.120175</td>\n      <td>-0.014717</td>\n      <td>0.094264</td>\n    </tr>\n    <tr>\n      <th>6484</th>\n      <td>test_6484</td>\n      <td>MYVSNGKDTCQLLGPVSLFVQTLMGMTAVIVLLVKRNYEHPRRKMI...</td>\n      <td>Fungi</td>\n      <td>273</td>\n      <td>0.045067</td>\n      <td>0.240210</td>\n      <td>0.010367</td>\n      <td>0.108304</td>\n      <td>-0.067205</td>\n      <td>-0.121369</td>\n      <td>...</td>\n      <td>0.088721</td>\n      <td>0.016557</td>\n      <td>-0.171101</td>\n      <td>0.151766</td>\n      <td>-0.244892</td>\n      <td>0.108346</td>\n      <td>0.181892</td>\n      <td>0.037327</td>\n      <td>0.023023</td>\n      <td>0.076660</td>\n    </tr>\n    <tr>\n      <th>6485</th>\n      <td>test_6485</td>\n      <td>MYVWPCAVVLAQYLWFHRRSLPGKAILEIGAGVSLPGILAAKCGAE...</td>\n      <td>Metazoa</td>\n      <td>190</td>\n      <td>-0.080344</td>\n      <td>0.316687</td>\n      <td>-0.070094</td>\n      <td>-0.051003</td>\n      <td>-0.046601</td>\n      <td>-0.147084</td>\n      <td>...</td>\n      <td>0.466889</td>\n      <td>-0.217825</td>\n      <td>-0.149523</td>\n      <td>-0.105499</td>\n      <td>0.234158</td>\n      <td>0.122640</td>\n      <td>0.242110</td>\n      <td>-0.011383</td>\n      <td>-0.079558</td>\n      <td>-0.202546</td>\n    </tr>\n    <tr>\n      <th>6486</th>\n      <td>test_6486</td>\n      <td>MYYHNQHQGKSILSSSRMPISSERHPFLRGNGTGDSGLILSTDAKP...</td>\n      <td>Viridiplantae</td>\n      <td>402</td>\n      <td>0.127888</td>\n      <td>0.349859</td>\n      <td>0.000780</td>\n      <td>0.060009</td>\n      <td>0.036233</td>\n      <td>-0.261401</td>\n      <td>...</td>\n      <td>0.217066</td>\n      <td>0.015657</td>\n      <td>-0.191005</td>\n      <td>-0.040256</td>\n      <td>-0.503746</td>\n      <td>0.049176</td>\n      <td>0.112414</td>\n      <td>-0.062682</td>\n      <td>-0.050713</td>\n      <td>0.236100</td>\n    </tr>\n    <tr>\n      <th>6487</th>\n      <td>test_6487</td>\n      <td>MYYIGHPSYYRKHIEHVCFQHSGILKKRNYQKNQKKYIMKLNESAM...</td>\n      <td>Fungi</td>\n      <td>464</td>\n      <td>0.030072</td>\n      <td>0.241007</td>\n      <td>-0.088931</td>\n      <td>0.090009</td>\n      <td>-0.036844</td>\n      <td>-0.013518</td>\n      <td>...</td>\n      <td>0.272390</td>\n      <td>-0.045815</td>\n      <td>-0.004871</td>\n      <td>-0.012933</td>\n      <td>-0.179958</td>\n      <td>-0.076372</td>\n      <td>0.001504</td>\n      <td>0.009703</td>\n      <td>0.001611</td>\n      <td>0.047157</td>\n    </tr>\n  </tbody>\n</table>\n<p>6488 rows × 1284 columns</p>\n</div>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "X_test = test_data.drop(columns=[\"sequence\", \"ID\", \"Kingdom\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "      seq_len  mean_embeddings_1  mean_embeddings_2  mean_embeddings_3  \\\n0         306           0.138000           0.078087           0.048324   \n1         327          -0.051710           0.353796           0.149786   \n2         159          -0.002891           0.152937           0.173129   \n3         358          -0.091884           0.188601           0.056167   \n4         302          -0.138956           0.168996           0.114288   \n...       ...                ...                ...                ...   \n6483      138          -0.081279           0.184097          -0.011704   \n6484      273           0.045067           0.240210           0.010367   \n6485      190          -0.080344           0.316687          -0.070094   \n6486      402           0.127888           0.349859           0.000780   \n6487      464           0.030072           0.241007          -0.088931   \n\n      mean_embeddings_4  mean_embeddings_5  mean_embeddings_6  \\\n0              0.035530           0.013417          -0.096783   \n1             -0.109090           0.012032          -0.096914   \n2              0.075425           0.024429          -0.159387   \n3              0.081018          -0.026512          -0.300105   \n4             -0.081320           0.028298           0.004822   \n...                 ...                ...                ...   \n6483           0.120396           0.008164          -0.088014   \n6484           0.108304          -0.067205          -0.121369   \n6485          -0.051003          -0.046601          -0.147084   \n6486           0.060009           0.036233          -0.261401   \n6487           0.090009          -0.036844          -0.013518   \n\n      mean_embeddings_7  mean_embeddings_8  mean_embeddings_9  ...  \\\n0             -0.385766          -0.128247          -0.294128  ...   \n1             -0.229879           0.037871          -0.073446  ...   \n2             -0.158628          -0.047328          -0.057284  ...   \n3             -0.611468           0.430214          -0.352542  ...   \n4             -0.206359          -0.109191          -0.229107  ...   \n...                 ...                ...                ...  ...   \n6483          -0.202314           0.020914          -0.209818  ...   \n6484          -0.087903           0.112842          -0.137679  ...   \n6485          -0.213666           0.057450          -0.035045  ...   \n6486          -0.311381           0.097338          -0.264904  ...   \n6487          -0.212639          -0.046941          -0.003183  ...   \n\n      mean_embeddings_1271  mean_embeddings_1272  mean_embeddings_1273  \\\n0                 0.383642             -0.084738             -0.215819   \n1                 0.402158             -0.074534             -0.124143   \n2                 0.250508              0.014100             -0.208263   \n3                 0.171207             -0.241675             -0.362721   \n4                 0.482548             -0.155571             -0.209955   \n...                    ...                   ...                   ...   \n6483              0.087244             -0.027435             -0.153783   \n6484              0.088721              0.016557             -0.171101   \n6485              0.466889             -0.217825             -0.149523   \n6486              0.217066              0.015657             -0.191005   \n6487              0.272390             -0.045815             -0.004871   \n\n      mean_embeddings_1274  mean_embeddings_1275  mean_embeddings_1276  \\\n0                -0.065172             -0.514831              0.005591   \n1                 0.052344             -0.414115              0.131673   \n2                 0.034511             -0.681030             -0.005970   \n3                -0.036837              0.262394              0.242967   \n4                 0.011263             -0.416560              0.123376   \n...                    ...                   ...                   ...   \n6483             -0.108225             -0.276514             -0.072615   \n6484              0.151766             -0.244892              0.108346   \n6485             -0.105499              0.234158              0.122640   \n6486             -0.040256             -0.503746              0.049176   \n6487             -0.012933             -0.179958             -0.076372   \n\n      mean_embeddings_1277  mean_embeddings_1278  mean_embeddings_1279  \\\n0                 0.045531             -0.137004             -0.135382   \n1                 0.130051             -0.029759             -0.169029   \n2                 0.219935             -0.058027             -0.035240   \n3                 0.107660             -0.192324             -0.115085   \n4                 0.061400              0.007495             -0.038448   \n...                    ...                   ...                   ...   \n6483              0.066795              0.120175             -0.014717   \n6484              0.181892              0.037327              0.023023   \n6485              0.242110             -0.011383             -0.079558   \n6486              0.112414             -0.062682             -0.050713   \n6487              0.001504              0.009703              0.001611   \n\n      mean_embeddings_1280  \n0                 0.012397  \n1                 0.024629  \n2                 0.027064  \n3                 0.064569  \n4                -0.025895  \n...                    ...  \n6483              0.094264  \n6484              0.076660  \n6485             -0.202546  \n6486              0.236100  \n6487              0.047157  \n\n[6488 rows x 1281 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq_len</th>\n      <th>mean_embeddings_1</th>\n      <th>mean_embeddings_2</th>\n      <th>mean_embeddings_3</th>\n      <th>mean_embeddings_4</th>\n      <th>mean_embeddings_5</th>\n      <th>mean_embeddings_6</th>\n      <th>mean_embeddings_7</th>\n      <th>mean_embeddings_8</th>\n      <th>mean_embeddings_9</th>\n      <th>...</th>\n      <th>mean_embeddings_1271</th>\n      <th>mean_embeddings_1272</th>\n      <th>mean_embeddings_1273</th>\n      <th>mean_embeddings_1274</th>\n      <th>mean_embeddings_1275</th>\n      <th>mean_embeddings_1276</th>\n      <th>mean_embeddings_1277</th>\n      <th>mean_embeddings_1278</th>\n      <th>mean_embeddings_1279</th>\n      <th>mean_embeddings_1280</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>306</td>\n      <td>0.138000</td>\n      <td>0.078087</td>\n      <td>0.048324</td>\n      <td>0.035530</td>\n      <td>0.013417</td>\n      <td>-0.096783</td>\n      <td>-0.385766</td>\n      <td>-0.128247</td>\n      <td>-0.294128</td>\n      <td>...</td>\n      <td>0.383642</td>\n      <td>-0.084738</td>\n      <td>-0.215819</td>\n      <td>-0.065172</td>\n      <td>-0.514831</td>\n      <td>0.005591</td>\n      <td>0.045531</td>\n      <td>-0.137004</td>\n      <td>-0.135382</td>\n      <td>0.012397</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>327</td>\n      <td>-0.051710</td>\n      <td>0.353796</td>\n      <td>0.149786</td>\n      <td>-0.109090</td>\n      <td>0.012032</td>\n      <td>-0.096914</td>\n      <td>-0.229879</td>\n      <td>0.037871</td>\n      <td>-0.073446</td>\n      <td>...</td>\n      <td>0.402158</td>\n      <td>-0.074534</td>\n      <td>-0.124143</td>\n      <td>0.052344</td>\n      <td>-0.414115</td>\n      <td>0.131673</td>\n      <td>0.130051</td>\n      <td>-0.029759</td>\n      <td>-0.169029</td>\n      <td>0.024629</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>159</td>\n      <td>-0.002891</td>\n      <td>0.152937</td>\n      <td>0.173129</td>\n      <td>0.075425</td>\n      <td>0.024429</td>\n      <td>-0.159387</td>\n      <td>-0.158628</td>\n      <td>-0.047328</td>\n      <td>-0.057284</td>\n      <td>...</td>\n      <td>0.250508</td>\n      <td>0.014100</td>\n      <td>-0.208263</td>\n      <td>0.034511</td>\n      <td>-0.681030</td>\n      <td>-0.005970</td>\n      <td>0.219935</td>\n      <td>-0.058027</td>\n      <td>-0.035240</td>\n      <td>0.027064</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>358</td>\n      <td>-0.091884</td>\n      <td>0.188601</td>\n      <td>0.056167</td>\n      <td>0.081018</td>\n      <td>-0.026512</td>\n      <td>-0.300105</td>\n      <td>-0.611468</td>\n      <td>0.430214</td>\n      <td>-0.352542</td>\n      <td>...</td>\n      <td>0.171207</td>\n      <td>-0.241675</td>\n      <td>-0.362721</td>\n      <td>-0.036837</td>\n      <td>0.262394</td>\n      <td>0.242967</td>\n      <td>0.107660</td>\n      <td>-0.192324</td>\n      <td>-0.115085</td>\n      <td>0.064569</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>302</td>\n      <td>-0.138956</td>\n      <td>0.168996</td>\n      <td>0.114288</td>\n      <td>-0.081320</td>\n      <td>0.028298</td>\n      <td>0.004822</td>\n      <td>-0.206359</td>\n      <td>-0.109191</td>\n      <td>-0.229107</td>\n      <td>...</td>\n      <td>0.482548</td>\n      <td>-0.155571</td>\n      <td>-0.209955</td>\n      <td>0.011263</td>\n      <td>-0.416560</td>\n      <td>0.123376</td>\n      <td>0.061400</td>\n      <td>0.007495</td>\n      <td>-0.038448</td>\n      <td>-0.025895</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6483</th>\n      <td>138</td>\n      <td>-0.081279</td>\n      <td>0.184097</td>\n      <td>-0.011704</td>\n      <td>0.120396</td>\n      <td>0.008164</td>\n      <td>-0.088014</td>\n      <td>-0.202314</td>\n      <td>0.020914</td>\n      <td>-0.209818</td>\n      <td>...</td>\n      <td>0.087244</td>\n      <td>-0.027435</td>\n      <td>-0.153783</td>\n      <td>-0.108225</td>\n      <td>-0.276514</td>\n      <td>-0.072615</td>\n      <td>0.066795</td>\n      <td>0.120175</td>\n      <td>-0.014717</td>\n      <td>0.094264</td>\n    </tr>\n    <tr>\n      <th>6484</th>\n      <td>273</td>\n      <td>0.045067</td>\n      <td>0.240210</td>\n      <td>0.010367</td>\n      <td>0.108304</td>\n      <td>-0.067205</td>\n      <td>-0.121369</td>\n      <td>-0.087903</td>\n      <td>0.112842</td>\n      <td>-0.137679</td>\n      <td>...</td>\n      <td>0.088721</td>\n      <td>0.016557</td>\n      <td>-0.171101</td>\n      <td>0.151766</td>\n      <td>-0.244892</td>\n      <td>0.108346</td>\n      <td>0.181892</td>\n      <td>0.037327</td>\n      <td>0.023023</td>\n      <td>0.076660</td>\n    </tr>\n    <tr>\n      <th>6485</th>\n      <td>190</td>\n      <td>-0.080344</td>\n      <td>0.316687</td>\n      <td>-0.070094</td>\n      <td>-0.051003</td>\n      <td>-0.046601</td>\n      <td>-0.147084</td>\n      <td>-0.213666</td>\n      <td>0.057450</td>\n      <td>-0.035045</td>\n      <td>...</td>\n      <td>0.466889</td>\n      <td>-0.217825</td>\n      <td>-0.149523</td>\n      <td>-0.105499</td>\n      <td>0.234158</td>\n      <td>0.122640</td>\n      <td>0.242110</td>\n      <td>-0.011383</td>\n      <td>-0.079558</td>\n      <td>-0.202546</td>\n    </tr>\n    <tr>\n      <th>6486</th>\n      <td>402</td>\n      <td>0.127888</td>\n      <td>0.349859</td>\n      <td>0.000780</td>\n      <td>0.060009</td>\n      <td>0.036233</td>\n      <td>-0.261401</td>\n      <td>-0.311381</td>\n      <td>0.097338</td>\n      <td>-0.264904</td>\n      <td>...</td>\n      <td>0.217066</td>\n      <td>0.015657</td>\n      <td>-0.191005</td>\n      <td>-0.040256</td>\n      <td>-0.503746</td>\n      <td>0.049176</td>\n      <td>0.112414</td>\n      <td>-0.062682</td>\n      <td>-0.050713</td>\n      <td>0.236100</td>\n    </tr>\n    <tr>\n      <th>6487</th>\n      <td>464</td>\n      <td>0.030072</td>\n      <td>0.241007</td>\n      <td>-0.088931</td>\n      <td>0.090009</td>\n      <td>-0.036844</td>\n      <td>-0.013518</td>\n      <td>-0.212639</td>\n      <td>-0.046941</td>\n      <td>-0.003183</td>\n      <td>...</td>\n      <td>0.272390</td>\n      <td>-0.045815</td>\n      <td>-0.004871</td>\n      <td>-0.012933</td>\n      <td>-0.179958</td>\n      <td>-0.076372</td>\n      <td>0.001504</td>\n      <td>0.009703</td>\n      <td>0.001611</td>\n      <td>0.047157</td>\n    </tr>\n  </tbody>\n</table>\n<p>6488 rows × 1281 columns</p>\n</div>"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "n_rows = 6488\n",
    "#target = np.zeros((5 * n_rows, ))\n",
    "# y1 = y[\"Nucleus\"]\n",
    "# y2 = y[\"Cytoplasm\"]\n",
    "# y3 = y[\"Membrane\"]\n",
    "# y4 = y[\"Cell membrane\"]\n",
    "# y5 = y[\"Extracellular\"]\n",
    "with open(\"submission.csv\", \"w\") as f:\n",
    "    f.write(\"id, target\\n\")\n",
    "    for i in range(n_rows):\n",
    "        f.write(f\"test_{i}_Nucleus, {model.predict(X_test.to_numpy()[i].reshape(-1, 1281)).squeeze()}\\n\")\n",
    "        f.write(f\"test_{i}_Cytoplasm, {model2.predict(X_test.to_numpy()[i].reshape(-1, 1281)).squeeze()}\\n\")\n",
    "        f.write(f\"test_{i}_Membrane, {model3.predict(X_test.to_numpy()[i].reshape(-1, 1281)).squeeze()}\\n\")\n",
    "        f.write(f\"test_{i}_Cell membrane, {model4.predict(X_test.to_numpy()[i].reshape(-1, 1281)).squeeze()}\\n\")\n",
    "        f.write(f\"test_{i}_Extracellular, {model5.predict(X_test.to_numpy()[i].reshape(-1, 1281)).squeeze()}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.94038904, 0.68708295, 0.8400452 , ..., 0.27817994, 0.9972597 ,\n       0.06430247], dtype=float32)"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test.to_numpy().reshape(-1, 1281)).squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}